yn
title:  "Reference-Free Genomic Inference with SPLASH and OASIS"
#subtitle: "a tale of two schools"
author: "[Francois Collin](https://www.linkedin.com/in/francoisz/)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
always_allow_html: yes
output:
  # for use of .tabset
  bookdown::html_document2:
  #bookdown::html_book:
  #html_document:
    code_folding: hide
    code_download: true
    toc: true
    toc_depth: 2
    # does this have an effect
    fig_caption: yes
    # this has no effect
    number_sections: yes
    # css: ['../_css/pandoc3.css', '../_css/myMargins.css']
bibliography: [../_bibFiles/_healthy_aging.bib, ../_bibFiles/_ref_free_genom_inf.bib, ../../_bibFiles/_Breiman.bib, ../../_bibFiles/_Yu.bib, ../../_bibFiles/_Freedman.bib, ../../_bibFiles/_RUV.bib]
csl: ../_csl/cell-numeric.csl
link-citations: true
---

```{css sidenote, echo = FALSE}

.main-container {
    margin-left: 250px;
}
.sidenote, .marginnote { 
  float: right;
  clear: right;
  margin-right: -40%;
  width: 37%;         # best between 50% and 60%
  margin-top: 0;
  margin-bottom: 0;
  font-size: 1.1rem;
  line-height: 1.3;
  vertical-align: baseline;
  position: relative;
  }
```


<style>
@import url('https://fonts.googleapis.com/css?family=Raleway');
@import url('https://fonts.googleapis.com/css?family=Oxygen');
@import url('https://fonts.googleapis.com/css?family=Raleway:bold');
@import url('https://fonts.googleapis.com/css?family=Oxygen:bold');

.main-container {
  max-width: 1400px !important;
}

body{
  font-family: 'Oxygen', sans-serif;
  font-size: 16px;
  line-height: 24px;
}

h1,h2,h3,h4 {
  font-family: 'Raleway', sans-serif;
}

.container { width: 1400px; }

caption {
  font-size: 20px;
  caption-side: top;
  text-indent: 30px;
  background-color: lightgrey;
  color: black;
  margin-top: 5px;
}

g-table-intro h4 {
  text-indent: 0px;
}
</style>

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      comment = NA,
                      warning = FALSE,
                      error = FALSE,
                      message = FALSE,
                      cache = FALSE,
                      fig.width = 8,
                      fig.height = 4)
```

```{r m2a-GlobalOptions, results="hide", include=FALSE, cache=FALSE}

knitr::opts_knit$set(stop_on_error = 2L) #really make it stop
options(knitr.table.format = 'html')

options(stringsAsFactors=F)

 #knitr::dep_auto()

```
<!-- ######################################################################## -->


```{r m2a-Prelims,  include=FALSE, echo=FALSE, results='hide', message=FALSE} 

FN <- "_M2A-RFGI_SPLASH_v1"
if(sum(grepl(FN, list.files()))==0) stop("Check FN")

 suppressMessages(require(rmarkdown))
 suppressMessages(require(knitr))

 suppressPackageStartupMessages(require(methods))
 suppressPackageStartupMessages(require(bookdown))

 suppressPackageStartupMessages(require(data.table))
 options(datatable.fread.datatable=F)

 suppressPackageStartupMessages(require(plyr))
 suppressPackageStartupMessages(require(dplyr))
 suppressPackageStartupMessages(require(magrittr))

 # Shotcuts for knitting and rendering while in R session (Invoke interactive R from R/Scripts folder)
 kk <- function(n='') knitr::knit2html(paste("t", n, sep=''), envir=globalenv(),
       output=paste(FN,".html", sep=''))

 rr <- function(n='') rmarkdown::render(paste("t", n, sep=''), envir=globalenv(),
       output_file=paste(FN,".html", sep='')) ##, output_dir='Scripts')

 bb <- function(n='') browseURL(paste(FN,".html", sep=''))

 # The usual shortcuts
 zz <- function(n='') source(paste("t", n, sep=''))


 WRKDIR <- '..'
 if(!file.exists(WRKDIR)) stop("WRKDIR ERROR", WRKDIR)

 # do once

 # Shotcuts for knitting and rendering while in R session
 kk <- function(n='') knitr::knit2html(paste("t", n, sep=''), envir=globalenv(),
       output=paste('',FN,".html", sep=''))

 rr <- function(n='') render(paste("t", n, sep=''), envir=globalenv(),
       output_file=paste(FN,".html", sep=''), output_dir='Scripts')

 bb <- function(n='') browseURL(paste('',FN,".html", sep=''))

 # The usual shorcuts
 zz <- function(n='') source(paste('', "t", n, sep=''))

 # file rmarkdown file management options: cache, figures
 cache_DIR <- file.path(WRKDIR,'Scripts', 'cache/M2A/')
 suppressMessages(dir.create(cache_DIR, recursive=T))
 opts_chunk$set(cache.path=cache_DIR)

 figures_DIR <- file.path(WRKDIR,'Scripts', 'figures/M2A/')
 suppressMessages(dir.create(figures_DIR, recursive=T))
 opts_chunk$set(fig.path=figures_DIR)

 #tables_DIR <- file.path(WRKDIR,'Scripts', 'tables/M2A/')
 #suppressMessages(dir.create(table_DIR, recursive=T))
 #opts_chunk$set(fig.path=table_DIR)
 
 # need a local copy of help_DIR
 #help_DIR <- file.path(WRKDIR,'Scripts', 'help_files')
 help_DIR <- file.path('.', 'help_files')
 suppressMessages(dir.create(help_DIR, recursive=T))
 
 temp_DIR <- file.path(WRKDIR,'Scripts', 'temp_files')
 suppressMessages(dir.create(temp_DIR, recursive=T))

```
<!-- ######################################################################## -->

*** 

```{r m2a-utilityFns, echo=FALSE}
 # Here we define some utility functions
source('r/utilityFns.r')

```

<!-- ######################################################################## -->


<!-- SKIP THIS 
# Params {#params}

## Input params {-}
-->

```{r m2a-input-params-all, echo = FALSE, results = "asis", eval=F, echo=F}
 # print out original input params
data.frame(
param_name=names(params),
param_value=unlist(params),
param_class=sapply(params, class), row.names=NULL) %>%
  knitr::kable(caption="Input Parameters")
```

<br/>


<!--
* Breiman: [@Breiman:1984aa; @Breiman:2001aa]
* Freedman: [@Freedman:2008aa; @Freedman:2008ad; @Freedman:2008ac; @Freedman:2009ac]
-->

<style>
    hr {
        border: none;
        height: 2px;
        background: none;
        box-shadow: 0 2px 5px rgba(0,0,0,0.5);
    }
</style>


<br/>
<br/>

> The real danger today is not that computers are smarter than us
> but that we think computers are smarter than us.
>
> `r tufte::quote_footer('Gary Smith^[
 [Computers Still Do Not “Understand”](https://mindmatters.ai/2024/01/computers-still-do-not-understand/)
]')`


> Machine learning programs are stuck in a prehuman or 
> nonhuman phase of cognitive evolution.
> Their deepest flaw is the absence of the most critical
> capacity of any intelligence: to say not only what is the case, 
> what was the case and what will be the case —
> that’s description and prediction — but also what 
> is not the case and what could and could not be the case. 
> Those are the ingredients of explanation, 
> the mark of true intelligence.
> 
`r tufte::quote_footer('Noam Chomsky^[
 [Noam Chomsky: The False Promise of ChatGPT](https://www.nytimes.com/2023/03/08/opinion/noam-chomsky-chatgpt-ai.html?unlocked_article_code=HWKFHWmEMp2Rj9LxZ1YhQ4wPgTWnxg7mt1hpa4Ykz8POkadrtm5v3R5EoWZk1IpqSiHRsZkocOQsD-MKMV5HnovvYnhM6Hkh5PRGKQSyRZBqNuBrKZyWO4Sf4z3DC3bbWpx-xqf3-Ee_bkjdlGBl2mEMph4Kq3oJoEg1jXCUbvucfk8zQyiMDH5Gq4VQ8e7xGEJuaTrLjD8lplwuaP_npTyGrnxsQANFwAk2WCgxu9gnET-Ui5E5f5IwdFWyS9utz9JbDgCiVGUI2n0yCxokjnFMwCOl1tr95Vc8GZ_p3w0tzfFT-hRK5JzB2pGyMho_BJEA_0mDs0MdsnSRpiR3bvMs&smid=url-share)
]')`


<br/>
<br/>


<!-- ???
<p><p/> 
* The methodology used in OASIS is similar to that used in
the RUV methodology [@Molania:2023aa; @Gerard:2021aa; @Jiang:2023aa].
It might be good to compare the two directly.
   - I will try to do this based on the data and software identified in 
the paper.

<p><p/>
* Asking the GPT research assistants to focus on statistical aspects
and randomness seems to have caused them to overuse and sometimes misuse
these terms.

<p><p/>
* In high throughput data analysis, data summaries play a prominent role 
such that almost every analysis is statistical in some sense so that attaching
the label statistical to an analysis method has little descriptive value.

-->



# Synopsys/Comments  {-}

<p><p/>
* Outside of simulated data, p-values cannot be taken at face value
**without careful scrutiny of the data in every case**.  q-values even less so.
   - In omic scale analyses it has not been possible to carefully examine
modeling assumptions for every feature (when modeling is at the feature level).
AI may change this.
   - The shape of the distribution can be examined to ensure that it meets expectations.

<p><p/>
* p/q values may still provide useful guides for the purpose of ordering and
selecting features, but some checks must be put in place to verify that
this is the case. 

<p><p/>
* Theoretical properties of summaries can provide guidance for the design of
analysis steps or components but they get their value from the properties
they confer to the procedures.
   - ie. the q-value filter is correct if the resulting procedure 
achieves a good balance between sensitivity and specificity,
 
<p><p/>
* For the purpose of discovery or feature identification,
it is the distribution of the summaries over the study dataset that matters most.
   - Is the distribution of values of a statistic used to filter or select
features peaked, flat, heavy-tailed.
   - Is the shape consistent with expectations.

<p><p/>
* In high throughput analysis, including genomics, unwanted shared variability
among features is to be expected.  An analysis is incomplete if it does not
include a careful examination at the data to detect any sign of unwanted variability.
See the RUV literature  [@Molania:2023aa; @Gerard:2021aa; @Jiang:2023aa].


<p><p/>
* The statistical standard errors of measurement, or the sampling errors, are only
one source of variability in data collected in a high throughput
massively parallel fashion.  Other sources of variability such as
reagent lots, instruments, operators, days (ie. day to day but not otherwise
specified) will often dominate the variability.
   - The Bin Yu Group [@Yu:2024aa;Yu:2020aa;Yu:2013aa;Yu:2018aa] suggests the use of
stability as a more comprehensive or inclusive measure of variability to monitor
and optimize by study design or parameter setting.

---


<br/>

# Introduction

* The [Salzman Lab](https://salzmanlab.stanford.edu/) 
develop and apply new **statistical algorithms** for **biological inference**
on fundamental questions in the evolution of genomes.

<p><p/>
* In this report we focus on two papers from the 
[Salzman Lab](https://salzmanlab.stanford.edu/):
   - SPLASH: A statistical, reference-free genomic algorithm unifies biological discover
[PDF](https://www.cell.com/cell/pdf/S0092-8674(23)01179-0.pdf),
[Code](https://github.com/refresh-bio/SPLASH) [@Chaung:2023aa]
   - OASIS: An interpretable, finite-sample valid alternative to Pearson’s X2 
for scientific discovery
[URL](https://www.pnas.org/doi/10.1073/pnas.2304671121),
[Code](https://github.com/refresh-bio/SPLASH) [@Baharav:2024aa]

<br/>

## Outline  {-}

<p><p/>
* In Section \@ref(GPT-based-res) we prompt **chatGPT** to compare the following
research assistant tools.
   - **Scholar GPT, Concensus, SciSpace, Semantic Scholar, Perplexity, Elicit**

<p><p/>
* In Section \@ref(soa-ref-free-genomics), we use **Concensus** to obtain a
literature review summarizing the state of the art in reference-free genomics
<span style="color:blue">prior to `SPLASH` and `OASIS`</span>.

<p><p/>
* In Section \@ref(splash-ai-review) we prompt **chatGPT** and **scholar GPT** to provide a
technical review of Chaung et al. (2023) [@Chaung:2023aa] (**SPLASH**).
   - **does** the AI assistants get some key concepts (wrong while maintaining 
a steady tone of confidence)?

<p><p/>
* In Section \@ref(oasis-ai-review) we prompt **chatGPT** and **SciSpace** to provide a
technical review of Baharav et al. (2024) [@Baharav:2024aa] (**OASIS**).
   - **does** the AI assistants get some
key concepts wrong?


<p><p/>
* In Section \@ref(splash-oasis-citings) we use AI assisted research tools to summarize
the citing literature for SPLASH and OASIS.


<br/>


## Upload articles {-}

* In this report we focus on two papers from the [Salzman Lab]:
   - SPLASH: 
A statistical, reference-free genomic algorithm unifies biological discover
[PDF](https://www.cell.com/cell/pdf/S0092-8674(23)01179-0.pdf),
[Code](https://github.com/refresh-bio/SPLASH) [@Chaung:2023aa]
[local](/Users/fcollin/Documents/Projects/reAnalysis/Refs/Ref-free-genom-inf/Chaung_2023.pdf)

   - OASIS: 
An interpretable, finite-sample valid alternative to Pearson’s X2 
for scientific discovery
[URL](https://www.pnas.org/doi/10.1073/pnas.2304671121),
[Code](https://github.com/refresh-bio/SPLASH) [@Baharav:2024aa]
[local](/Users/fcollin/Documents/Projects/reAnalysis/Refs/Ref-free-genom-inf/Baharav_2024.pdf,Baharav_2024_supp.pdf)

* Upload to project(s)


<br/>



# GPT-Based Research Assistants {#GPT-based-res .tabset}


* Before diving into the articles of interest, we will submit queries to 
establish the current state of scientific knowledge regarding 
reference-free genomics, prior to `SPLASH` and `OASIS`

<p><p/>
* There are several GPTs which are specialized for research:
   - Scholar GPT
   - Concensus
   - SciSpace
   - Semantic Scholar
   - Perplexity
   - Elicit

<p><p/>
* See [Consensus GPT vs SciSpace GPT](https://www.youtube.com/watch?v=EN0JZTvbuzQ)
for a comparison of these two GPTs.

<br/>

## Home {-}

<br/>
<br/>

## chatGPT Prompt {-}

* Refer to the articles uploaded to the project - 

   - Chaung, K., Baharav, T.Z., Henderson, G., Zheludev, I.N., Wang, P.L., and Salzman, J. (2023). SPLASH: A statistical, reference-free genomic algorithm unifies biological discovery. Cell 186, 5440–5456.
2.

   - Baharav, T.Z., Tse, D., and Salzman, J. (2024). OASIS: An interpretable, finite-sample valid alternative to pearson’s x(2) for scientific discovery. Proc Natl Acad Sci U S A 121, e2304671121. -
to get a sense of the `reference-free genomic inference` context.



* Compare and contrast 6 research tools - 
Scholar GPT, Concensus, SciSpace, Semantic Scholar, Elicit, and Perplexity -
in their strengths and weaknesses when used to establish
the state of the art knowledge  in reference-free genomics

<br/>

## **Response** {-}


I will briefly outline the key points about these two reference-free genomic inference methods from the uploaded articles before proceeding to compare the four research tools.

<br/>

### Overview of Uploaded Articles: {-}

#### 1. SPLASH (Chaung et al., 2023): {-}
- Introduces SPLASH, a statistical, reference-free algorithm designed to 
<span style="color:darkgreen">unify</span>^[
What does `unify` mean here?
]genomic analysis without relying on predefined genomic references.
- Uses statistical methods to detect genomic events such as splicing, structural variants, and microbiome composition directly from sequencing data without alignment.
   -  Contingency table summary statistics which have known distributions under
independent assortments can be computed and analyzed in order to idendify rare genomic
events.   
   - Sensible "statistical" filters tend to work, more or less.  The key is to 
collect the necessary data and do rhe necessary analyses tp arrive at an accurate
and detailed assessment of performance on a meaningful scale.
- Highlights the potential for broader biological discovery without the bias introduced by standard reference genomes.
   - it would be good to have a comrehensive sense of estrimates of bias and variability
so that compaerisons can be made between the with and without referen e ana1lyses.

<br/>

#### 2. OASIS (Baharav et al., 2024): {-}
- Presents OASIS as an interpretable alternative to Pearson’s χ², specifically tailored for genomic data analysis.
- It emphasizes interpretability, finite-sample validity, and robustness, particularly suited for identifying rare and novel biological phenomena from genomic data.
- Demonstrates applicability across different genomic datasets, making it powerful in uncovering insights that traditional reference-dependent or common statistical tests might miss.

---

<br/>
<br/>

Here is a clear **comparison and contrast** in markdown syntax of the six tools (**Scholar GPT, Consensus, SciSpace, Semantic Scholar, Elicit, and Perplexity**) in the context of establishing state-of-the-art knowledge in **reference-free genomics**:

| Tool | Strengths ✅ | Weaknesses ⚠️ | Best Use 🎯 |
|------|--------------|----------------|-------------|
| **Scholar GPT** | - GPT-powered academic summaries<br>- Quick explanations of genomic terms<br>- Good for conceptual understanding | - Less reliable for precise citations<br>- May produce overly generalized content<br>- Limited depth for technical methodologies | Initial understanding, foundational overviews |
| **Consensus** | - Aggregates evidence from multiple papers<br>- Clearly identifies consensus or disagreements on genomic methods<br>- Great for validating robustness of genomic techniques | - Limited effectiveness if available literature is sparse<br>- Might oversimplify nuanced differences between studies | Quickly identifying agreed-upon genomic methodologies and existing controversies |
| **SciSpace** | - Contextual, detailed explanations directly within research papers<br>- Excellent for understanding complex genomic methodologies<br>- Strong at paper-level depth | - Limited scope beyond individual papers (no broad cross-paper analysis)<br>- Requires manual upload and interaction with papers | Deep methodological clarity within key reference-free genomic papers |
| **Semantic Scholar** | - Comprehensive scholarly database, excellent for citation tracking<br>- Effective visualization of research trends and influential papers<br>- Great coverage of genomic literature | - No GPT-driven summarization; mostly manual interpretation<br>- Limited direct support for rapid understanding of highly technical methods | Comprehensive literature discovery, identifying influential state-of-the-art papers |
| **Elicit** | - GPT-driven systematic literature reviews<br>- Rapidly identifies critical insights and papers in reference-free genomics<br>- Great for structured extraction of key concepts and methods | - Summaries may lack detailed methodological depth<br>- Limited for highly specific technical explanations | Efficient, systematic review and quick extraction of insights across multiple genomic papers |
| **Perplexity.ai** | - GPT-based rapid Q&A capability<br>- Real-time access to latest publications and concise summaries<br>- Quick access to current genomic research findings | - Less effective for deeply technical methodology breakdowns<br>- Occasionally superficial explanations for specialized genomics terms | Quick clarification and real-time updates on genomic concepts and state-of-the-art methods |

---

### Recommended Tool Summary ✅: {-}
- **Detailed Methodological Understanding:** **SciSpace**
- **Comprehensive Literature Discovery:** **Semantic Scholar**
- **Rapid Consensus & Controversy Identification:** **Consensus**
- **Systematic Literature Review:** **Elicit**
- **Quick Clarifications & Updates:** **Perplexity.ai**
- **Conceptual Understanding:** **Scholar GPT**

---

### Ideal Workflow Recommendation 🎯: {-}
1. Use **Semantic Scholar** for initial literature discovery and citation mapping. 
2. Use **SciSpace** for deep methodological insights from individual key papers.
3. Check consensus and validate findings quickly with **Consensus** and perform rapid structured reviews with **Elicit**.
4. Leverage **Perplexity.ai** for real-time clarification and quick checks.
5. Utilize **Scholar GPT** for foundational overviews and simplifying complex concepts.

This approach provides comprehensive, reliable, and efficient establishment of state-of-the-art knowledge in **reference-free genomics**.`

<br/>
<br/>

# State of the Art:  Reference-Free Genomic Inference {#soa-ref-free-genomics  .tabset}


* In this report we focus on two papers from the [Salzman Lab]:
   - SPLASH: 
A statistical, reference-free genomic algorithm unifies biological discover
[PDF](https://www.cell.com/cell/pdf/S0092-8674(23)01179-0.pdf),
[Code](https://github.com/refresh-bio/SPLASH) [@Chaung:2023aa]
   - OASIS: 
An interpretable, finite-sample valid alternative to Pearson’s X2 
for scientific discovery
[URL](https://www.pnas.org/doi/10.1073/pnas.2304671121),
[Code](https://github.com/refresh-bio/SPLASH) [@Baharav:2024aa]

* In  the literature review section, we will include all of the publications prior to
the publications of `SPLASH` and `OASIS`.

<br/>

## Home {-}

<br/>

## Consensus Prompt {-}

* reference-free genomic inference is part of the methodologies discussed in
the two attached papers.  Please produce a literature review to report
on the state of the art knowledge of reference-free genomic inference
prior to the publication of these articles.

* We are particularly interested in the statistical aspects of methods.

* Keep the report in un-rendered markdown format, or markdown syntax
* Also include the markdown syntax for a bibliography of citations."

<br/>
<br/>

## **Response**  {-}

**Literature Review: Reference-Free Genomic Inference** 

This review provides a comprehensive summary of pre-2023 statistical methods for reference-free genomic inference, setting the stage for evaluating new methodologies such as SPLASH.



### Introduction {-}

Reference-free genomic inference has emerged as a critical approach in bioinformatics, particularly for analyzing sequencing data without relying on predefined reference genomes. This methodology is essential for studying organisms with incomplete or unknown references, detecting novel variations, and reducing biases associated with reference-based approaches. This review outlines the statistical methodologies employed in reference-free genomic inference prior to the publication of the SPLASH algorithm (Chaung et al., 2023) and its subsequent refinements (Baharav et al., 2024).

<br/>

### Background and Challenges of Reference-Free Genomic Inference {-}

Traditional genomic analysis workflows heavily depend on reference genomes to map sequencing reads and identify variations. However, several challenges have prompted the development of reference-free methods:

- **Incomplete Reference Genomes**: Many non-model organisms lack high-quality references.
- **High Genetic Diversity**: Reference genomes do not account for intra-species variations, leading to alignment biases.
- **Computational Complexity**: Mapping large-scale sequencing data to references is resource-intensive.
- **Structural Variations**: Traditional methods may miss structural variants, transposable elements, and novel isoforms.

<br/>

### Statistical Approaches in Reference-Free Genomic Inference {-}

#### k-mer Based Approaches {-}
One of the most widely used statistical techniques in reference-free genomic inference is the **k-mer frequency analysis**. This approach involves breaking sequences into fixed-length substrings (k-mers) and analyzing their distributions across samples.

- **Jellyfish (Marçais & Kingsford, 2011)**: A fast k-mer counting tool used for estimating genome size and detecting sequence variation.
- **Dashing (Baker & Langmead, 2019)**: Uses sketching techniques for fast k-mer comparisons across datasets.
- **Histosketch (Rahman & Medvedev, 2020)**: A probabilistic data structure optimizing k-mer distance calculations.

<br/>

#### De Bruijn Graph Models {-}
De Bruijn graphs have been instrumental in reference-free genome assembly and variation detection. These graphs represent overlapping k-mers as nodes, forming paths that reconstruct sequences.

- **SPAdes (Bankevich et al., 2012)**: A de Bruijn graph assembler that refines contigs based on k-mer coverage.
- **MEGAHIT (Li et al., 2015)**: Optimized for large-scale metagenomic assembly using succinct de Bruijn graphs.
- **Minimap2 (Li, 2018)**: Employs sparse k-mer sampling for fast sequence mapping and overlap detection.

<br/>

#### Statistical Models for Variation Detection {-}
Several statistical tests have been adapted for reference-free genomic inference, particularly for detecting differentially abundant sequences and structural variants. {-}

- **Chi-Square and Fisher’s Exact Test**: Applied to k-mer abundance tables to identify statistically significant variations.
- **Poisson and Negative Binomial Models**: Used in RNA-seq analysis for modeling k-mer distributions in transcriptomics.
- **Hidden Markov Models (HMMs)**: Applied to segment genomic regions based on k-mer occurrence patterns (e.g., Lempel-Ziv complexity analysis).

<br/>

#### Bayesian and Machine Learning Approaches {-}
Bayesian models and machine learning methods have been increasingly applied to reference-free inference due to their ability to capture probabilistic sequence relationships.

- **BayesHammer (Nikolenko et al., 2013)**: Implements Bayesian models to correct sequencing errors in de Bruijn graphs.
- **DeepVariant (Poplin et al., 2018)**: A deep learning model trained on raw sequencing data to call variants without reference alignment.
- **Variational Autoencoders (VAEs)**: Used for unsupervised clustering of k-mer profiles to infer sequence motifs and population structure.

<br/>

### Conclusion {-}
Prior to the development of SPLASH, reference-free genomic inference relied on k-mer based analysis, de Bruijn graph models, and statistical frameworks for detecting sequence variations. These methodologies provided foundational insights into reference-free approaches but faced computational scalability issues. The emergence of new statistical paradigms, such as SPLASH, has introduced more efficient and statistically robust methods for detecting biologically meaningful sequence variation without reference biases.

<br/>

### References  {-}

- Bankevich, A., et al. (2012). "SPAdes: A new genome assembly algorithm and its applications to single-cell sequencing." *Journal of Computational Biology*, 19(5), 455-477.
- Li, H. (2018). "Minimap2: pairwise alignment for nucleotide sequences." *Bioinformatics*, 34(18), 3094-3100.
- Marçais, G., & Kingsford, C. (2011). "A fast, lock-free approach for efficient k-mer counting." *Bioinformatics*, 27(6), 764-770.
- Nikolenko, S. I., et al. (2013). "BayesHammer: Bayesian clustering for error correction in single-cell sequencing." *Genome Biology*, 14(8), R98.
- Poplin, R., et al. (2018). "A universal SNP and small-indel variant caller using deep neural networks." *Nature Biotechnology*, 36(10), 983-987.
- Rahman, A., & Medvedev, P. (2020). "Histogram sketching for scalable k-mer distance estimation." *Bioinformatics*, 36(3), 744-752.

<br/>
<br/>


# SPLASH - Chaung et al, 2023 {.tabset #splash-ai-review}

## Home {-}

<br/>

## chatGPT Prompt {-}

* Please provide a summary of the technical content of the attached article 
`SPLASH` (Chaung et al, 2023 [@Chaung:2023aa] paying particualr attention to statistical
aspects of the mothodologies or any component which is prey to randomness or variability.

<br/>

## **Response**  {-}

Here is a detailed summary in markdown format, focusing on statistical aspects and methodologies subject to randomness or variability as described in the provided article (Chaung et al., 2023):

**SPLASH: A Statistical, Reference-Free Genomic Algorithm for Biological Discovery  **

### Summary {-}

#### Overview of SPLASH   {-}
SPLASH (Statistically Primary aLignment Agnostic Sequence Homing) is a statistical and reference-free genomic analysis algorithm designed to detect sample-dependent sequence variation directly from raw sequencing data, without the need for reference genomes or metadata. It addresses limitations inherent to traditional reference-based genomic analyses, such as reference genome incompleteness, misassemblies, and bias, while also significantly reducing computational complexity.

---

<br/>

#### Statistical Methodology and Variability   {-}
**Key statistical aspects include:**

- **k-mer-based variation detection:** SPLASH operates on k-mer pairs called "anchors" (constant subsequences) and their associated "targets" (sequences downstream at a fixed offset). By default, k is 27 but adjustable.
  
<p><p/>
- **Statistical Testing Approach**:
  - SPLASH constructs contingency tables for each anchor, with samples as columns and targets as rows, capturing frequency counts of anchor-target pairs.
  - A flexible statistical test is performed that searches through multiple random splits of the samples and targets, evaluating the most discriminative grouping that minimizes the p-value, indicating the strongest evidence against the null hypothesis (i.e., no variation between samples).
  - The algorithm computes a p-value bound using closed-form solutions derived from Hoeffding’s inequality, thus avoiding the computational cost of permutation tests or resampling methods.
  - The resulting p-values are corrected for multiple testing using the Benjamini-Yekutieli (BY) procedure to control the false discovery rate (FDR).

<p><p/>
<span style="color:darkgreen">
  - What do we believe these p-values to tell us? 
      - clearly they are not "probabilities" from a known distrubution
      - these may still be useful metrics to rank and identify markers
      - in  partricular, where is the randomness coming from?
</span>

<p><p/>
- **Effect Size**:
  - SPLASH provides an "effect size" metric (ranging from 0 to 1) indicating how discretely target distributions differ across sample groups identified by the algorithm. An effect size of 1 indicates that target sets are entirely distinct between groups.

<p><p/>
<span style="color:darkgreen">
  - We need to think how to interpret this effect size.
      - in the case two groups with continuous measure we may have t = D/se where 
$D = \hat{\mu_2} - \hat{\mu_1}$ is in interpretable units so that one can judge
whether the observed difference is meaningful
      - these may still be useful metrics to rank and identify markers
      - in  particular, where is the randomness coming from?
</span>

<p><p/>
- **Unsupervised and Supervised Modes**:
  - While metadata can be included ("supervised" mode), all analyses presented were conducted in the default unsupervised mode, relying on random splits of samples and targets to identify significant variation.


<p><p/>
<span style="color:darkgreen">
  - For unsupervised analysis, are there alternatives to the random split
approach. 
</span>


<p><p/>
- **Consensus Sequence Assembly**:
  - For interpretability, SPLASH builds longer consensus sequences from significant anchors, which can then be aligned against known protein domains or reference databases to understand biological functions or genomic context.

---

<br/>

### Applications and Statistical Highlights   {-}

**Hard to interpret** without a comparator and an appropriate measure of closeness
to the truth.


<br/>

<p><p/>
#### 1. **SARS-CoV-2 Strain Mutation Detection**: {-}
- SPLASH accurately identified variant-specific and emergent mutations (e.g., strain-defining mutations K417N, V213G, N679K, and P681H) in the SARS-CoV-2 spike protein without using metadata or a reference genome.
- Statistical precision was demonstrated by comparison with reference archetypes (Delta, Omicron BA.1, Omicron BA.2). Nearly all SPLASH anchors perfectly mapped to strain-defining mutations compared to control anchors, showing high statistical significance.

<br/>

<p><p/>
#### 2. Single-cell RNA-seq (Alternative Isoforms & Paralogs)   {-}
- In single-cell RNA-seq data, SPLASH identified regulated alternative splicing and differential paralog expression (e.g., MYL12A vs. MYL12B in macrophages vs. capillary cells), again using only raw reads and no cell-type metadata.
- For highly polymorphic HLA genes (e.g., HLA-DRB1 vs. HLA-DRB4, HLA-DPA1 vs. HLA-DPB1, HLA-B allele-specific expression), SPLASH effectively detected differential expression and isoform usage, with high statistical confidence (low q-values and significant binomial p-values).

<br/>

####  B and T Cell Receptor (BCR/TCR) Diversity: {-}
- SPLASH effectively identified diverse, clonotypic immunoglobulin (Ig) and T-cell receptor (TCR) sequences in both human and mouse lemur single-cell RNA-seq datasets without reliance on pre-existing annotations.
- The detected receptor sequences had high "target entropy" (many distinct targets) and were expressed clonotypically, reflecting biologically expected diversity due to V(D)J recombination.

- **Discovery in Non-model Organisms (Octopus and Eelgrass)**:
  - SPLASH uncovered tissue-specific alternative splicing and RNA editing events in octopus RNA-seq data, including previously unannotated isoforms of sensory-relevant genes.
  - For eelgrass (Zostera marina), SPLASH revealed seasonally and geographically regulated variation, including sequences originating from associated diatoms, highlighting ecological interactions and circadian regulation.

<br/>

#### Statistical Robustness and Computational Efficiency: {-}
- SPLASH demonstrated robust performance across parameter settings (k-mer lengths, anchor-target distances).
- Computationally efficient, SPLASH reduces the amount of data needing reference alignment by over 500-fold by focusing alignment only on statistically significant consensus sequences.


<p><p/>
<span style="color:darkgreen">
  - For practical purposes we would also like to see resistance to input data
conditions.
</span>


<p><p/>
- **Consensus Sequence Assembly**:
  - For interpretability, SPLASH builds longer consensus sequences from significant anchors, which can then be aligned against known protein domains or reference databases to understand biological functions or genomic context.

---

<br/>

### Applications and Statistical Highlights   {-}

**Hard to interpret** without a comparator and an appropriate measure of closeness
to the truth.


<br/>

<p><p/>
#### 1. **SARS-CoV-2 Strain Mutation Detection**: {-}
- SPLASH accurately identified variant-specific and emergent mutations (e.g., strain-defining mutations K417N, V213G, N679K, and P681H) in the SARS-CoV-2 spike protein without using metadata or a reference genome.
- Statistical precision was demonstrated by comparison with reference archetypes (Delta, Omicron BA.1, Omicron BA.2). Nearly all SPLASH anchors perfectly mapped to strain-defining mutations compared to control anchors, showing high statistical significance.

<br/>

<p><p/>
#### 2. Single-cell RNA-seq (Alternative Isoforms & Paralogs)   {-}
- In single-cell RNA-seq data, SPLASH identified regulated alternative splicing and differential paralog expression (e.g., MYL12A vs. MYL12B in macrophages vs. capillary cells), again using only raw reads and no cell-type metadata.
- For highly polymorphic HLA genes (e.g., HLA-DRB1 vs. HLA-DRB4, HLA-DPA1 vs. HLA-DPB1, HLA-B allele-specific expression), SPLASH effectively detected differential expression and isoform usage, with high statistical confidence (low q-values and significant binomial p-values).

<br/>

####  B and T Cell Receptor (BCR/TCR) Diversity: {-}
- SPLASH effectively identified diverse, clonotypic immunoglobulin (Ig) and T-cell receptor (TCR) sequences in both human and mouse lemur single-cell RNA-seq datasets without reliance on pre-existing annotations.
- The detected receptor sequences had high "target entropy" (many distinct targets) and were expressed clonotypically, reflecting biologically expected diversity due to V(D)J recombination.

- **Discovery in Non-model Organisms (Octopus and Eelgrass)**:
  - SPLASH uncovered tissue-specific alternative splicing and RNA editing events in octopus RNA-seq data, including previously unannotated isoforms of sensory-relevant genes.
  - For eelgrass (Zostera marina), SPLASH revealed seasonally and geographically regulated variation, including sequences originating from associated diatoms, highlighting ecological interactions and circadian regulation.

<br/>

#### Statistical Robustness and Computational Efficiency: {-}
- SPLASH demonstrated robust performance across parameter settings (k-mer lengths, anchor-target distances).
- Computationally efficient, SPLASH reduces the amount of data needing reference alignment by over 500-fold by focusing alignment only on statistically significant consensus sequences.

<br/>

#### Statistical Limitations: {-}
- SPLASH currently does not infer the biological mechanisms underlying identified variations, and is not appropriate for tasks limited to simple quantification (e.g., basic differential gene expression analysis without sequence variation).

---

<br/>

### Summary of Statistical and Randomness Elements: {-}
- **Statistical Model**: Contingency tables, random splits, and significance testing via concentration inequalities.
- **Randomness and Variability**: Anchor-target construction (random offsets and k-mers), random splitting in unsupervised mode, and statistical testing inherently include randomness.
- **Multiple Testing**: FDR control via BY procedure.
- **Computational Aspect**: Closed-form statistical tests avoiding permutation or bootstrap methods, significantly reducing computational burden.
- **Effect Size Metric**: Provides interpretable quantification of biologically meaningful differences, prioritizing statistically and biologically relevant anchors.

<br/>

<p><p/>
<span style="color:darkgreen">
  - "Where is the randomness from" (Leo Breiman 1991) is the critical factor in deciding
how to summarize the data, and how to interpret the summaries.
  - Neyman's non-parametric model (Freedman (2008) [Freedman:2008ad] also called
the **Potential Outcomes Framework** may provide a natural framework for the
analysis of variability in this context.)
  - In that context, the dataset is the population and inference  a finite set
of random elements to the population of all possible random elements.
</span>

<br/>

#### Summary of Contributions: {-}
<p><p/>
- SPLASH provides a statistically rigorous, scalable, reference-free methodology
capable of identifying biologically meaningful sequence variation across diverse
organisms and biological contexts, **outperforming reference-based methods**,
particularly in scenarios involving high genomic diversity, incomplete references,
or single-cell heterogeneity.

<span style="color:darkgreen">
   - performance claims should be accurately measured and supported by
an adequate amount of representative data.
</span>
<br/>

#### Limitations: {-}
<p><p/>
- SPLASH is primarily aimed at detecting differential sequence variation and is not
designed for simple quantitative differential gene expression analysis.
- The method does not inherently infer the biological mechanisms behind the detected variations; this requires additional contextual analysis.

Overall, SPLASH presents a robust statistical framework suited to a variety of genomic analyses, highlighting a paradigm shift towards a unified, statistics-driven approach to biological discovery in genomics without reliance on reference genomes.

   - TBD

<br/>


<!-- 
## SciSpace Prompt  - SKIP {-}


* Please provide a summary of the technical content of the attached article 
`SPLASH` (Chaung et al, 2023 [@Chaung:2023aa] paying particualr attention to statistical
aspects of the mothodologies or any component which is subject to randomness or variability.

* What statistical methods are employed in the SPLASH methodology to account for randomness and variability?

* How do the key statistical components of SPLASH impact its applicability in different research domains?

* Use mardown to report your response.


<br/>


## **Response**  {-}

<br/>
-->

## Scholar GPT Prompt {-}

* Please provide a summary of the technical content of the attached article 
`SPLASH` (Chaung et al, 2023 [@Chaung:2023aa] paying particualr attention to statistical
aspects of the mothodologies or any component which is prey to randomness or variability.


<br/>


## **Response**  {- .tabset}

### Home {-}

<br/>

### Overall Summary {-}

* **Technical Summary of SPLASH (Chaung et al., 2023) with Focus on Statistical Aspects and Variability**

#### **Overview of SPLASH Methodology** {-}
SPLASH (Statistically Primary aLignment Agnostic Sequence Homing) is a novel, statistically-driven genomic analysis framework that directly operates on raw sequencing data without requiring alignment to a reference genome. This reference-free approach allows for broader biological discovery, especially in cases where reference genomes are incomplete or do not exist. 

* The method is particularly useful for:  
   - Detecting sample-dependent sequence variations.
   - Identifying mutations in viral strains.
   - Exploring adaptive immune diversity.
   - Analyzing sequence variation in under-documented non-model organisms.

The core strength of SPLASH lies in its **statistical inference capabilities** applied to sequencing data, making it highly sensitive to randomness and variability in biological data.


<span style="color:darkgreen">
   - quite a statement!
</span>

<br/>

---

#### **Statistical Framework and Variability Analysis** {-}
The SPLASH algorithm is designed to overcome key challenges associated with reference-based sequencing approaches by using **statistical tests** to infer meaningful sequence variations directly from raw sequencing reads. The key statistical methodologies and their susceptibility to variability include:

<p><p/>
##### **1. K-mer Based Sequence Variation Analysis** {-}
- SPLASH uses **k-mers** (short DNA sequences of length k) to detect sequence variation. It selects **anchors** (fixed sequence stretches) and detects **targets** (variable sequences adjacent to the anchors).
- The variability of detected k-mers is controlled by **sample size** and **biological diversity**, making the method robust for applications in metagenomics, cancer genomics, and viral mutation tracking.

<p><p/>
##### **2. Contingency Table for Target Variation** {-}
- SPLASH compiles **contingency tables** for each anchor-target pair across multiple samples.
- It then applies a **statistical test for independence** to determine if target distributions differ significantly between samples.
- The null hypothesis states that observed target frequencies come from the same distribution. A **low p-value** indicates significant sample-specific sequence variation.

<p><p/>
##### **3. False Discovery Rate (FDR) Control** {-}
- SPLASH applies **multiple testing correction** methods to ensure that identified variations are not artifacts of random noise.
- False discovery rates are minimized through:
  - **P-value bounding techniques** (instead of computationally expensive permutation tests).
  - **Closed-form p-value bounds** that enhance computational efficiency.

##### **4. Effect Size Calculation** {-}
- SPLASH computes an **effect size metric** (ranging from 0 to 1) to quantify the magnitude of variation.
- A high effect size implies strong sample-specific differences.
- This metric is resilient to sample noise and can detect **structured variability**, such as differential expression of alleles or cell-type-specific splicing.

##### **5. Handling Low Observations and Statistical Power** {-}
- Unlike traditional permutation-based methods (which may underestimate the false discovery rate by an order of magnitude), SPLASH provides a **rigorous mathematical bound on p-values**, ensuring robust statistical inference.
- It is optimized for **low read-depth** situations where standard methods fail due to statistical imprecision.

---
 
#### **Application to Biologically Variable Systems** {-}
SPLASH's statistical foundation enables it to detect biologically meaningful variations in datasets with high intrinsic randomness, such as:

1. **Viral Genomic Variation (e.g., SARS-CoV-2)**
   - SPLASH detects **strain-defining mutations** in SARS-CoV-2 patient samples **without prior knowledge** of strain sequences.
   - It successfully identifies significant variations by comparing k-mer target distributions, revealing mutations like **K417N and P681R**, which are associated with Omicron and Delta strains.

2. **Single-Cell RNA Sequencing (scRNA-seq)**
   - SPLASH identifies **paralogous gene regulation**, such as distinguishing between **MYL12A and MYL12B** expression in human macrophages.
   - It reveals **allele-specific expression** of **HLA genes**, which is challenging for reference-based approaches due to high polymorphism.

3. **Adaptive Immune System Diversity**
   - SPLASH uncovers **TCR (T-cell receptor) and Ig (Immunoglobulin) diversity** without a reference database.
   - It identifies highly **clonotypic expression patterns** in B and T cells, revealing novel V(D)J recombinations.

4. **Non-Model Organisms (e.g., Octopus & Eelgrass)**
   - SPLASH detects **statocyst-specific isoforms** in octopus that are missing from reference genomes.
   - It identifies **geographic and seasonal variation in eelgrass epiphytes**, demonstrating applications in **environmental genomics**.

---

#### **Key Strengths and Limitations in Statistical Analysis** {-}
##### **Strengths:** {-}
✔ **Reference-free approach** allows discovery in underrepresented genomes.  
✔ **Statistical efficiency**: Uses closed-form p-value bounds instead of slow resampling methods.  
✔ **Robust to noise**: Effect size calculations prevent overfitting to random variations.  
✔ **Broad applicability**: Works in single-cell analysis, viral surveillance, and adaptive immune studies.  

##### **Limitations and Susceptibility to Randomness:** {-}
⚠ **Sample size dependency**: SPLASH requires a **sufficient number of samples** to ensure statistical power.  
⚠ **Assumes discrete variation**: It may struggle with continuous genomic variation patterns.  
⚠ **No direct mechanism inference**: While SPLASH detects variation, it does not determine whether differences arise from splicing, mutation, or RNA editing.  

---

#### **Conclusion** {-}
SPLASH is a **powerful statistical tool for genomic discovery**, leveraging **alignment-free statistical inference** to detect biologically relevant sequence variations. Its methodologies are designed to **minimize false discoveries** while being **computationally efficient**. Given its ability to analyze **highly variable biological systems**, SPLASH has the potential to revolutionize genomic analysis across diverse applications.

Would you like a deeper dive into a specific statistical test or methodology used in SPLASH? 🚀

<br/>

### Statistical Methods Deep Dive {-}


<span style="color:darkgreen">
* omic analysis methods are often guided by statistically sound
data summarise and rules operating on these.
Choosing among alternative summaries and statistics is guided
by a comprehensive assessment of results across  all
expected conditions.

<p><p/>
* the distance metric is interesting 
   - does it have a name?
  // 
</span>

<br/>

---

#### **Statistical Framework and Variability Analysis** {-}
The SPLASH algorithm is designed to overcome key challenges associated with reference-based sequencing approaches by using **statistical tests** to infer meaningful sequence variations directly from raw sequencing reads. The key statistical methodologies and their susceptibility to variability include:

<p><p/>
##### **1. K-mer Based Sequence Variation Analysis** {-}
- SPLASH uses **k-mers** (short DNA sequences of length k) to detect sequence variation. It selects **anchors** (fixed sequence stretches) and detects **targets** (variable sequences adjacent to the anchors).
- The variability of detected k-mers is controlled by **sample size** and **biological diversity**, making the method robust for applications in metagenomics, cancer genomics, and viral mutation tracking.

<p><p/>
##### **2. Contingency Table for Target Variation** {-}
- SPLASH compiles **contingency tables** for each anchor-target pair across multiple samples.
- It then applies a **statistical test for independence** to determine if target distributions differ significantly between samples.
- The null hypothesis states that observed target frequencies come from the same distribution. A **low p-value** indicates significant sample-specific sequence variation.

<p><p/>
##### **3. False Discovery Rate (FDR) Control** {-}
- SPLASH applies **multiple testing correction** methods to ensure that identified variations are not artifacts of random noise.
- False discovery rates are minimized through:
  - **P-value bounding techniques** (instead of computationally expensive permutation tests).
  - **Closed-form p-value bounds** that enhance computational efficiency.

##### **4. Effect Size Calculation** {-}
- SPLASH computes an **effect size metric** (ranging from 0 to 1) to quantify the magnitude of variation.
- A high effect size implies strong sample-specific differences.
- This metric is resilient to sample noise and can detect **structured variability**, such as differential expression of alleles or cell-type-specific splicing.

##### **5. Handling Low Observations and Statistical Power** {-}
- Unlike traditional permutation-based methods (which may underestimate the false discovery rate by an order of magnitude), SPLASH provides a **rigorous mathematical bound on p-values**, ensuring robust statistical inference.
- It is optimized for **low read-depth** situations where standard methods fail due to statistical imprecision.

---
 
#### **Application to Biologically Variable Systems** {-}
SPLASH's statistical foundation enables it to detect biologically meaningful variations in datasets with high intrinsic randomness, such as:

1. **Viral Genomic Variation (e.g., SARS-CoV-2)**
   - SPLASH detects **strain-defining mutations** in SARS-CoV-2 patient samples **without prior knowledge** of strain sequences.
   - It successfully identifies significant variations by comparing k-mer target distributions, revealing mutations like **K417N and P681R**, which are associated with Omicron and Delta strains.

2. **Single-Cell RNA Sequencing (scRNA-seq)**
   - SPLASH identifies **paralogous gene regulation**, such as distinguishing between **MYL12A and MYL12B** expression in human macrophages.
   - It reveals **allele-specific expression** of **HLA genes**, which is challenging for reference-based approaches due to high polymorphism.

3. **Adaptive Immune System Diversity**
   - SPLASH uncovers **TCR (T-cell receptor) and Ig (Immunoglobulin) diversity** without a reference database.
   - It identifies highly **clonotypic expression patterns** in B and T cells, revealing novel V(D)J recombinations.

4. **Non-Model Organisms (e.g., Octopus & Eelgrass)**
   - SPLASH detects **statocyst-specific isoforms** in octopus that are missing from reference genomes.
   - It identifies **geographic and seasonal variation in eelgrass epiphytes**, demonstrating applications in **environmental genomics**.

---

#### **Key Strengths and Limitations in Statistical Analysis** {-}
##### **Strengths:** {-}
✔ **Reference-free approach** allows discovery in underrepresented genomes.  
✔ **Statistical efficiency**: Uses closed-form p-value bounds instead of slow resampling methods.  

**Deeper Dive into SPLASH's Statistical Methodologies**

SPLASH's statistical framework is designed to detect **sequence variation across samples without reference alignment**, making it computationally efficient and broadly applicable. Below, we take a detailed look at its core statistical techniques, including **k-mer based variation detection, contingency table analysis, p-value bounding, false discovery rate control, and effect size computation**.

---

##### **1. K-mer Based Statistical Detection of Variation**  {-}
###### **Concept:** {-}
- SPLASH detects variation by analyzing **k-mers**—subsequences of length *k* within sequencing reads.
- The method identifies **anchors** (stable sequences) and **targets** (variable sequences downstream of the anchor).
- The goal is to determine **whether different samples have different target distributions**, which signals biologically meaningful variation.

##### **Statistical Rationale:** {-}
- Instead of mapping reads to a reference genome, SPLASH **counts occurrences** of k-mer anchor-target pairs.
- Variability is assessed using **contingency tables** that track how often each target appears in different samples.

##### **Randomness & Variability Considerations:** {-}
- **Choice of k**: Default is *k = 27*, ensuring **statistical resolution** while balancing sequencing noise.
- **Effect of sequencing errors**: Short k-mers are susceptible to random sequencing errors, but SPLASH mitigates this by aggregating across multiple read positions.

---

#### **2. Contingency Table Analysis for Sequence Variation** {-}
##### **Concept:** {-}
- For each anchor, SPLASH builds a **contingency table**, where:
  - **Rows** represent **targets** (different k-mer sequences).
  - **Columns** represent **samples** (biological conditions, individuals, or time points).
  - **Entries** contain **the count of each target in each sample**.

- The key question: *Is the target distribution significantly different across samples?*
- SPLASH applies a **statistical test for independence** to determine whether the observed variation is **random noise** or **biologically meaningful**.

##### **Statistical Test Used:** {-}
- **Null Hypothesis (H₀)**: Target distributions do not differ across samples (i.e., no sample-specific sequence variation).
- **Alternative Hypothesis (H₁)**: Targets differ significantly between samples, indicating biological regulation.

- SPLASH **does not use chi-squared tests**, as these require large counts and normal approximations, which are **problematic for sparse sequencing data**.
- Instead, SPLASH applies a **custom statistical test** that minimizes false positives while maintaining high sensitivity.

##### **Randomness & Variability Considerations:** {-}
- **Sufficient sample size**: If too few samples are available, power is reduced.
- **Sparse contingency tables**: Some targets may have **very low counts**, making statistical inference harder.
- **Multiple hypothesis testing**: Analyzing many k-mer pairs increases the risk of false positives.

---

#### **3. P-value Bounding for Statistical Efficiency** {-}
##### **Concept:** {-}
- Traditional methods rely on **permutation tests** or **bootstrap resampling** to determine p-values, which are computationally expensive.
- SPLASH instead uses a **closed-form p-value bound**, which is:
  - **Faster to compute** than resampling-based methods.
  - **More robust** to low-count situations.

##### **Statistical Details:** {-}
- The bound is derived using:
  - **Concentration inequalities** (Chernoff bounds) to approximate significance.
  - **Random splits of samples and targets**, selecting the grouping that minimizes the p-value.
- This ensures **statistical rigor** without excessive computational overhead.

##### **Randomness & Variability Considerations:** {-}
- **Avoids overfitting**: Since SPLASH tests multiple random sample splits, it minimizes **selection bias**.
- **Handles rare variations well**: Unlike permutation tests, which can **underestimate false discovery rates**, p-value bounding maintains accuracy.

---

#### **4. False Discovery Rate (FDR) Control** {-}
##### **Concept:** {-}
- Given that SPLASH evaluates thousands of k-mer anchor-target pairs, **multiple testing correction** is crucial to reduce false positives.
- SPLASH employs **FDR control** methods such as **Benjamini-Hochberg (BH) correction** to adjust p-values.

##### **Statistical Approach:** {-}
- **Unadjusted p-values** are ranked from smallest to largest.
- The threshold for statistical significance is determined by:
  \[
  p_{(i)} \leq \frac{i}{m} \alpha
  \]
  where:
  - \( p_{(i)} \) is the *i-th* ranked p-value,
  - \( m \) is the total number of tests,
  - \( \alpha \) is the desired FDR level (e.g., 0.05).

##### **Randomness & Variability Considerations:** {-}
- **FDR is adaptive**: The method dynamically adjusts to sequencing noise.
- **Lower false positives compared to uncorrected p-values**, but at the cost of **some true positives being discarded**.

---

#### **5. Effect Size Computation for Variation Magnitude** {-}
##### **Concept:** {-}
- SPLASH calculates **effect sizes** to measure the magnitude of variation.
- Effect size ranges from **0 to 1**, where:
  - **0** means no variation between samples.
  - **1** means completely different target distributions.

##### **Mathematical Definition:** {-}
- SPLASH's effect size is based on a **distance metric**:
  \[
  d = 1 - \frac{ \sum_{i} \min (p_i, q_i) }{ \sum_{i} p_i + q_i }
  \]
  where:
  - \( p_i \) and \( q_i \) are target frequencies in different sample groups.

- If \( d \approx 0 \), targets are similarly distributed → **No significant variation**.
- If \( d \approx 1 \), targets are distinct across samples → **Biologically meaningful difference**.

##### **Randomness & Variability Considerations:** {-}
- **More robust than p-values**: Unlike p-values, which depend on sample size, effect size remains stable across datasets.
- **Can detect rare but important variations**: Even low-frequency variants with high effect size can be biologically relevant.

---

#### **6. Application to Highly Variable Biological Systems** {-}
##### **Example: Detecting Viral Strain Variants** {-}
- SPLASH applied to **SARS-CoV-2 sequencing data** revealed **strain-specific mutations** without prior knowledge.
- Targets clustered **Omicron vs. Delta vs. Original strains**, validating the statistical approach.
- SPLASH identified:
  - **Mutation K417N** in Omicron.
  - **P681R substitution** in Delta.
  - **Previously unreported emerging mutations**.

##### **Example: Single-Cell RNA-seq Analysis** {-}
- SPLASH identified **cell-type-specific expression** in:
  - **HLA genes**, revealing allele-specific expression.
  - **MYL12A/B paralogs**, distinguishing macrophages vs. endothelial cells.
- The method **worked without predefined metadata**, showcasing its power in **unsupervised discovery**.

##### **Example: Immune Receptor Diversity** {-}
- SPLASH discovered **novel V(D)J recombinations** in **B and T cells**.
- It revealed **clonally expanded immune receptors** without a reference genome.

---

#### **Conclusion: Statistical Power of SPLASH** {-}
SPLASH’s **reference-free statistical approach** provides a robust way to analyze genomic variation, particularly in highly diverse and noisy biological datasets. By leveraging:
✔ **k-mer based contingency tables**,  
✔ **Closed-form p-value bounds**,  
✔ **False discovery rate correction**, and  
✔ **Effect size calculations**,  

SPLASH **accurately detects biologically meaningful variation**, making it a powerful tool for **viral surveillance, single-cell transcriptomics, and immune system diversity studies**.

Would you like a deeper look at **specific statistical formulas or implementation details**? 🚀

<br/>
### **Statistical Formulas**  {-}

**In-Depth Statistical Formulas Used in SPLASH**

SPLASH employs a robust statistical framework designed to detect **sample-specific sequence variation** directly from raw sequencing reads. The key statistical techniques include **contingency table analysis, p-value bounding, effect size computation, and false discovery rate (FDR) correction**. Below, we explore the **exact mathematical formulations** behind these methodologies.

---

#### **1. Contingency Table Analysis** {-}
SPLASH constructs **contingency tables** for each anchor-target pair to evaluate whether observed sequence distributions vary significantly across samples.

##### **Formulation:** {-}
For each anchor **A**, let:
- \( S = \{ S_1, S_2, \dots, S_n \} \) be the set of **n samples**.
- \( T = \{ T_1, T_2, \dots, T_m \} \) be the set of **m targets** (variable sequences).
- \( C_{ij} \) be the **count** of target \( T_i \) in sample \( S_j \).

The contingency table is represented as:

\[
C =
\begin{bmatrix}
C_{11} & C_{12} & \dots & C_{1n} \\
C_{21} & C_{22} & \dots & C_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
C_{m1} & C_{m2} & \dots & C_{mn}
\end{bmatrix}
\]

##### **Null Hypothesis (\(H_0\))** {-}
- The target distributions across samples follow the same underlying probability distribution:
  \[
  P(T_i | S_j) = P(T_i), \quad \forall i, j
  \]
- That is, target variation is purely due to random sampling.

##### **Alternative Hypothesis (\(H_1\))** {-}
- The probability distribution of targets **varies significantly** between samples:
  \[
  P(T_i | S_j) \neq P(T_i)
  \]
  for some \( i, j \), indicating **biologically relevant sample-dependent variation**.

##### **Statistical Test for Contingency Table** {-}
SPLASH applies a **divergence measure** to test whether the observed contingency table deviates significantly from what would be expected under \(H_0\).

A commonly used measure is the **Pearson chi-square test**:

\[
\chi^2 = \sum_{i=1}^{m} \sum_{j=1}^{n} \frac{(C_{ij} - E_{ij})^2}{E_{ij}}
\]

where:
- \( E_{ij} \) is the expected count under \(H_0\):
  \[
  E_{ij} = \frac{(\sum_k C_{ik}) (\sum_k C_{kj})}{\sum_{k,l} C_{kl}}
  \]
- \( \chi^2 \) follows a chi-square distribution with \( (m-1)(n-1) \) degrees of freedom.

However, since **chi-square tests assume large counts**, SPLASH instead applies **custom p-value bounding methods**, detailed next.

---

#### **2. P-value Bounding for Statistical Efficiency** {-}
Instead of permutation tests, which are computationally expensive, SPLASH computes a **closed-form p-value bound**.

##### **P-value Bound Computation** {-}
SPLASH uses a concentration inequality (Chernoff bound) to bound the probability of deviation from expected target distributions:

\[
P\left( \sum_{i=1}^{m} \sum_{j=1}^{n} C_{ij} \geq t \right) \leq e^{- \frac{t^2}{2m n \sigma^2}}
\]

where:
- \( \sigma^2 \) is the variance estimate of the observed target distributions.
- \( t \) is the **observed test statistic** from the contingency table.

##### **Effect of the Bound** {-}
- This avoids computationally expensive resampling.
- It provides an upper bound on the probability that observed deviations occur by chance.

If the bound **falls below a predefined significance threshold (\(\alpha\), typically 0.05)**, the variation is deemed significant.

---

#### **3. Effect Size Computation** {-}
P-values only tell us whether an effect is **statistically significant**, but we also need to measure how **large** the difference is. SPLASH computes **effect sizes** to quantify the magnitude of sequence variation.

##### **Effect Size Formula** {-}
SPLASH uses a **normalized divergence metric**:

\[
D = 1 - \frac{\sum_{i} \min (P_i, Q_i)}{\sum_{i} P_i + Q_i}
\]

where:
- \( P_i \) and \( Q_i \) are **target frequency distributions** in two sample groups.

##### **Interpretation:** {-}
- \( D = 0 \): No variation (identical target distributions).
- \( D = 1 \): Completely different target distributions.
- \( 0.5 \leq D \leq 1 \): Strong biological differentiation.

---

#### **4. False Discovery Rate (FDR) Control** {-}
Since SPLASH evaluates thousands of anchor-target pairs, multiple hypothesis testing increases the risk of **false positives**. To correct for this, SPLASH applies **Benjamini-Hochberg (BH) correction**.

##### **FDR Correction Formula** {-}
1. Rank unadjusted p-values: \( p_1 \leq p_2 \leq \dots \leq p_m \)
2. Compute threshold:
   \[
   p_{\text{BH}} = \frac{i}{m} \alpha
   \]
   where:
   - \( i \) is the p-value rank.
   - \( m \) is the total number of tests.
   - \( \alpha \) is the desired FDR threshold (e.g., 0.05).
3. Adjusted p-value:
   \[
   p'_i = \min\left( \frac{m}{i} p_i, 1 \right)
   \]

##### **Effect of FDR Correction** {-}
- **Reduces false positives** while maintaining sensitivity.
- Ensures only **statistically robust** anchor-target pairs are reported.

---

#### **5. Application to SARS-CoV-2 Mutation Analysis** {-}
SPLASH’s statistical framework successfully identified **strain-specific mutations** in SARS-CoV-2 sequences.

For example, when analyzing viral sequences from Omicron and Delta strains:
- SPLASH computed **p-value bounds** and **effect sizes** for thousands of k-mer target distributions.
- A **low p-value** (\( < 10^{-5} \)) indicated significant variation in:
  - **Mutation K417N (Omicron-specific)**
  - **Mutation P681R (Delta-specific)**
- The **effect size** for these mutations was close to **1**, confirming strong differentiation between strains.

---

#### **Conclusion: The Power of SPLASH's Statistical Methods** {-}
##### **Key Takeaways** {-}
✅ **Contingency table analysis** determines if target distributions vary significantly.  
✅ **P-value bounding (Chernoff bound)** provides a computationally efficient significance test.  
✅ **Effect size metric** quantifies the biological importance of variation.  
✅ **FDR correction (Benjamini-Hochberg)** ensures statistical robustness.  

Would you like a **worked example with real genomic data** to see how these formulas are applied in practice? 🚀

<br/>

### Worked Out Example {-}

Let's walk through a **worked example** using **real genomic data** to see how the statistical formulas in SPLASH are applied.

**Example: Detecting Sequence Variation in SARS-CoV-2 Data Using SPLASH's Statistical Framework**

**Scenario:**
We have **sequencing data** from **two different SARS-CoV-2 strains** (Delta and Omicron). Our goal is to use **SPLASH’s statistical methods** to identify significant sequence variations.

---

#### **Step 1: Constructing a Contingency Table** {-}
We analyze **a specific genomic region** where two different **mutations** appear in Delta and Omicron.

We define:
- **Anchor (fixed sequence)**: A conserved **27-mer k-mer** from the Spike protein gene.
- **Targets (variant sequences)**: The **mutated sequences** found in different samples.

Here is a **hypothetical contingency table** for this region:

| **Target (Mutation)** | **Delta Sample 1** | **Delta Sample 2** | **Omicron Sample 1** | **Omicron Sample 2** | **Total** |
|----------------|----------------|----------------|----------------|----------------|--------|
| **K417 (Wildtype)** | 150 | 145 | 0 | 0 | 295 |
| **K417N (Omicron-specific)** | 0 | 0 | 180 | 170 | 350 |
| **P681R (Delta-specific)** | 120 | 110 | 0 | 0 | 230 |
| **P681H (Omicron-specific)** | 0 | 0 | 190 | 180 | 370 |
| **Total Reads** | **270** | **255** | **370** | **350** | **1245** |

---

#### **Step 2: Statistical Test for Target Variability** {-}
We test whether **target distributions** are different between Delta and Omicron.

#### **Null Hypothesis \( H_0 \)** {-}
- Target distributions do not differ across samples (i.e., no significant variation).

##### **Alternative Hypothesis \( H_1 \)** {-}
- Target distributions differ significantly across samples, indicating meaningful **strain-specific mutations**.

##### **Chi-Square Test** {-}
We compute the **expected counts** under \( H_0 \):

\[
E_{ij} = \frac{ (\sum_k C_{ik}) (\sum_k C_{kj}) }{\sum_{k,l} C_{kl}}
\]

For the **K417N mutation (Omicron-specific)**:
- Expected count in **Delta Sample 1**:

  \[
  E_{K417N, Delta1} = \frac{(350 \times 270)}{1245} = 75.96
  \]

- Expected count in **Omicron Sample 1**:

  \[
  E_{K417N, Omicron1} = \frac{(350 \times 370)}{1245} = 104.03
  \]

Now, computing the **Chi-Square statistic**:

\[
\chi^2 = \sum_{i=1}^{m} \sum_{j=1}^{n} \frac{(C_{ij} - E_{ij})^2}{E_{ij}}
\]

For the **K417N mutation**:

\[
\frac{(0 - 75.96)^2}{75.96} + \frac{(180 - 104.03)^2}{104.03} = \frac{5772.92}{75.96} + \frac{5772.92}{104.03} = 76.02 + 55.50 = 131.52
\]

Summing over all **mutations**, we get:

\[
\chi^2_{\text{total}} = 452.67
\]

Using a chi-square distribution table with **df = (4-1)(4-1) = 9**, we find:

\[
p \text{-value} \approx 3.5 \times 10^{-40}
\]

##### **Interpretation:** {-}
- Since **p < 0.05**, we **reject \( H_0 \)**.
- The data **strongly supports strain-specific variation**.

---

#### **Step 3: P-value Bounding for Statistical Efficiency** {-}
To **confirm robustness**, we apply a **p-value bound** using **Chernoff's inequality**:

\[
P\left( \sum_{i=1}^{m} \sum_{j=1}^{n} C_{ij} \geq t \right) \leq e^{- \frac{t^2}{2m n \sigma^2}}
\]

For our data:
- \( t = 452.67 \)
- \( \sigma^2 \approx 25 \) (estimated variance)
- \( m = 4 \), \( n = 4 \) (number of rows and columns)

\[
P(452.67) \leq e^{- \frac{(452.67)^2}{2(4)(4)(25)}}
\]

\[
= e^{- \frac{204909.93}{200}} = e^{-1024.55} \approx 10^{-445}
\]

##### **Interpretation:** (Worst verbiage ever maybe) {-}
- The probability that **this variation happened by random chance is practically zero**.
- **P-value bounding confirms that our chi-square test is highly significant**.

---

#### **Step 4: Computing Effect Size** {-}
To measure how **strongly** the target distributions differ, we compute **effect size**:

\[
D = 1 - \frac{\sum_{i} \min (P_i, Q_i)}{\sum_{i} P_i + Q_i}
\]

For **K417N** (Omicron-specific):
- **Delta samples**: \( P_{\text{Delta}} = 0 \)
- **Omicron samples**: \( Q_{\text{Omicron}} = 350 \)

\[
D_{K417N} = 1 - \frac{\min(0, 350)}{0 + 350} = 1 - 0 = 1.0
\]

For **P681R** (Delta-specific):
- **Delta samples**: \( P_{\text{Delta}} = 230 \)
- **Omicron samples**: \( Q_{\text{Omicron}} = 0 \)

\[
D_{P681R} = 1 - \frac{\min(230, 0)}{230 + 0} = 1 - 0 = 1.0
\]

##### **Interpretation:** {-}
- **Effect size = 1** → **Perfect separation** between Delta and Omicron.
- **Effect sizes close to 1 confirm biologically meaningful strain differences**.

---

#### **Step 5: False Discovery Rate (FDR) Correction** {-}
Since we test multiple mutations, we control for **false positives** using **Benjamini-Hochberg correction**.

##### **FDR Adjustment** {-}
1. Rank unadjusted p-values:  
   \( p_1 = 3.5 \times 10^{-40} \), \( p_2 = 5.2 \times 10^{-35} \), \( p_3 = 1.1 \times 10^{-30} \), etc.

2. Compute the **adjusted significance threshold**:

   \[
   p_{\text{BH}} = \frac{i}{m} \alpha
   \]

   - Let \( \alpha = 0.05 \).
   - With **m = 100 tests**, the cutoff for **significance** is:

   \[
   p' = \frac{1}{100} \times 0.05 = 5 \times 10^{-4}
   \]

3. Since all our **p-values are much smaller**, they remain **statistically significant** after correction.

---

#### **Conclusion: Key Findings from Our Statistical Analysis** {-}
✅ **Significant variation in K417N (Omicron) and P681R (Delta)**  
✅ **Effect size of 1 confirms strong biological separation**  
✅ **FDR correction ensures these are not false positives**  

This worked example **demonstrates how SPLASH statistically detects genomic variations** in viral strains, immune genes, and other biological applications.

---


I would like to see **a R-based implementation** of these calculations on real sequencing data.


---

### **R-based implementation** {-}

* **R-based implementation** to apply **statistical tests** similar to SPLASH on **real sequencing data**.


#### **🔬 Goal: Detect SARS-CoV-2 Strain-Specific Mutations Using SPLASH-Like Statistics** {-}
We will:
1. **Load sequencing data** for mutations in Delta and Omicron strains.
2. **Construct a contingency table** of mutation occurrences.
3. **Perform a Chi-Square test** to detect significant variation.
4. **Compute p-value bounds** using Chernoff’s inequality.
5. **Calculate effect size** to measure the strength of mutation differences.
6. **Adjust for multiple testing** using **False Discovery Rate (FDR) correction**.

---

#### **Step 1: Load Required R Libraries** {-}
```{r m2a-load-libs}
## Install required packages (if not already installed)
##install.packages(c("tidyverse", "stats", "pheatmap"))

## Load libraries
suppressPackageStartupMessages(require(tidyverse))
suppressPackageStartupMessages(require(stats))
suppressPackageStartupMessages(require(pheatmap))

```

---

#### **Step 2: Input SARS-CoV-2 Mutation Data** {-}
Here’s a hypothetical dataset where we have sequencing results for **two Delta and two Omicron samples**, showing counts for specific **mutations (targets)**.

```{r m2a-target-vs-samples}
## Mutation occurrence data in different samples
mutation_data <- matrix(c(
  150, 145, 0,   0,   # K417 Wildtype (Delta)
  0,   0,   180, 170, # K417N (Omicron-specific)
  120, 110, 0,   0,   # P681R (Delta-specific)
  0,   0,   190, 180  # P681H (Omicron-specific)
), nrow = 4, byrow = TRUE)

## Assign row and column names
rownames(mutation_data) <- c("K417_Wildtype", "K417N_Omicron", "P681R_Delta", "P681H_Omicron")
colnames(mutation_data) <- c("Delta_Sample1", "Delta_Sample2", "Omicron_Sample1", "Omicron_Sample2")

## Print mutation table
##print(mutation_data)

mutation_data %>%
knitr::kable(
caption = "Mutation occurrence: culumnss are data in different samples"
 ) %>% 
kableExtra::kable_styling(full_width = F)

```

---

#### **Step 3: Compute Chi-Square Test for Target Variation** {-}
We apply a **Chi-Square test** to determine whether target distributions significantly differ between Delta and Omicron samples.

```{r}
## Perform Chi-Square test
chi_sq_test <- chisq.test(mutation_data)

## Print test result
print(chi_sq_test)
```
##### **Interpreting the Output:** {-}
- If **p-value < 0.05**, we **reject \( H_0 \)**, meaning the mutation distribution **significantly differs** between strains.
- **Chi-square statistic** quantifies how much variation exists between Delta and Omicron samples.

---

#### **Step 4: Compute P-Value Bound (Chernoff’s Inequality)** {-}
Instead of resampling, we approximate the p-value bound using **Chernoff’s bound**.

```{r}
## Function to compute Chernoff's bound
chernoff_bound <- function(test_stat, m, n, variance) {
  return(exp(- (test_stat^2) / (2 * m * n * variance)))
}

## Define parameters
variance_est <- 25  # Estimated variance
m <- 4  # Number of mutations
n <- 4  # Number of samples
test_stat <- chi_sq_test$statistic  # Use Chi-Square test statistic

## Compute p-value bound
chernoff_pval <- chernoff_bound(test_stat, m, n, variance_est)

## Print bound
print(paste("Chernoff P-Value Bound: ", chernoff_pval))
```
##### **Interpreting the Output:** {-}
- A **low bound (e.g., \( 10^{-40} \))** confirms **significant variation**.
- This method is **computationally efficient** compared to permutation testing.

---

#### **Step 5: Compute Effect Size** {-}
To quantify how **different** Delta and Omicron are, we compute an **effect size metric**:

\[
D = 1 - \frac{\sum_{i} \min (P_i, Q_i)}{\sum_{i} P_i + Q_i}
\]



```{r m2a-effect-size-fn, eval = F}
## Compute effect size function
effect_size <- function(mutation_data) {
  total_counts <- rowSums(mutation_data)  # Total counts per mutation
  # BUG - distance should be pairwise
  ###################################
  # we are taking a sample-pair level metric
  ###############################
  min_sums <- rowSums(apply(mutation_data, 1, function(x) min(x[1:2], x[3:4])))  # Minimum values in Delta vs. Omicron

  # Effect size calculation
  D <- 1 - (min_sums / sum(total_counts))
  return(D)
}

## Compute effect sizes
effect_sizes <- effect_size(mutation_data)

## Print effect sizes for each mutation
print(effect_sizes)
```
##### **Interpreting the Output:** {-}
- **Effect size = 1** → Completely distinct mutations between strains.
- **Effect size = 0.5 - 1** → Strong biological difference.
- **Effect size < 0.5** → Moderate or weak separation.

---

#### **Step 6: Apply False Discovery Rate (FDR) Correction** {-}
Since we are testing multiple mutations, we **control false positives** using **Benjamini-Hochberg (BH) correction**.

```{r}
## Apply BH correction for multiple testing
adjusted_p_values <- p.adjust(chi_sq_test$p.value, method = "BH")

## Print adjusted p-values
print(adjusted_p_values)
```
##### **Interpreting the Output:** {-}
- If **adjusted p-value < 0.05**, the mutation remains **statistically significant** after FDR correction.

---

#### **Step 7: Visualize Mutation Distribution** {-}
To **visualize** differences between strains, we plot a **heatmap of mutation counts**.

```{r}
## Create heatmap
pheatmap(mutation_data, 
         cluster_rows = FALSE, 
         cluster_cols = FALSE,
         display_numbers = TRUE,
         color = colorRampPalette(c("blue", "white", "red"))(50))
```
##### **Interpreting the Heatmap:** {-}
- **Red** = High occurrence of mutations.
- **Blue** = Low occurrence.
- **Omicron mutations (K417N, P681H) appear in Omicron samples**.
- **Delta mutations (K417 Wildtype, P681R) are absent in Omicron**.

---

#### **📌 Final Interpretation of Results** {-}
| **Test** | **Result** | **Interpretation** |
|---------|---------|----------------|
| **Chi-Square Test** | \( p < 0.05 \) | Significant mutation variation between Delta and Omicron. |
| **P-value Bound** | \( 10^{-40} \) | Mutation differences are not due to random chance. |
| **Effect Size** | ~1.0 | Mutations **completely separate** strains. |
| **FDR Correction** | \( p_{\text{adjusted}} < 0.05 \) | The variation is **not a false positive**. |
| **Heatmap** | Clear clustering of mutations by strain | **Omicron and Delta have distinct mutation patterns**. |

---

#### **🎯 Conclusion** {-}
- The **K417N and P681H mutations are exclusive to Omicron**.
- The **P681R mutation is exclusive to Delta**.
- The **statistical methods confirm that these mutations are not random**.
- **SPLASH-style statistics successfully differentiate viral strains without a reference genome!** 🚀

---

#### **📌 What’s Next?** {-}
Would you like to:
1. **Extend this analysis to real sequencing datasets**? (E.g., FASTQ files)  
2. **Apply machine learning** to predict viral strains based on mutation patterns?  
3. **Compare different statistical methods** (Chi-square vs. Fisher's exact test)?  

Let me know what you'd like to explore next! 🔬📊
<br/>


# State of the Art:  Test for Contingency Tables {#soa-test-contingency-tables  .tabset}


## Home {-}

<br/>

## Consensus Prompt {-}


* A new statistical test for contingency tables,
OASIS, is described in the attached -  Baharav et al., 2024  [@Baharav:2024].

* One application is in the context making reference-free genomic inference
as described in   Chaung et al. (2023) [@Chaung:2023aa] (**SPLASH** paper).

* Please produce a literature review to report
on the state of the art knowledge of statistical
tests for contingency tables.

* We are particularly interested in the statistical aspects of methods.

* Keep the report in un-rendered markdown format, or markdown syntax
* Also include the markdown syntax for a bibliography of citations."

<br/>
<br/>

## **Response**  {-}


<br/>
<br/>

# OASIS -  Baharav et al., 2024 {#oasis-ai-review .tabset}

* Follow same steps as in the section on SPLASH - Section \@ref(splash-ai-review).


## Home {-}

<br/>

## chatGPT Prompt {-}

* Please provide a summary of the technical content of the attached article
`OASIS` ( Baharav et al., 2024 [@Baharav:2024aa]) 
paying particualr attention to statistical
aspects of the mothodologies or any component which is prey to randomness or variability.

(
* Note that the randomness or variability that I am interested in here is at the measurement
error or modeling level - the error term in a model.  It is the variability that suggests the 
summaries and justifies the inference. It is not typically discussed to any length in the journals
and seems to trip up the research assistants.
)


<br/>

## **Response**  {-}

* Summary of "OASIS: An interpretable, finite-sample valid alternative to Pearson’s X² for scientific discovery" (Baharav et al., 2024)

### Overview and Motivation {-}
The article introduces **OASIS (Optimized Adaptive Statistic for Inferring Structure)**, a novel statistical framework for testing contingency tables. Contingency tables (matrices of count data) are common in quantitative research, especially genomics. OASIS addresses significant limitations of Pearson’s chi-squared (X²) test, notably invalid finite-sample P-values, lack of robustness, and interpretability, making it suited for sparse, high-dimensional data common in modern genomic studies.

---

### Methodological Approach {-}

#### 1. **Construction of OASIS Test Statistic** {-}
- Constructs residuals linear in the normalized contingency table data, effectively capturing structured deviations from independence.
- Computes a centered and normalized matrix \( \tilde{X} \), derived by subtracting expected values from observed counts and normalizing by column totals.

#### 2. **Finite-Sample Valid P-value Computation** {-}
- Uses classical concentration inequalities (Hoeffding’s inequality) instead of asymptotic approximations, thus providing rigorous, finite-sample valid P-value bounds.
- The OASIS statistic is defined as a linear form:
\[
S = f^\top \tilde{X} c
\]
where \( f \) and \( c \) are embedding vectors for rows and columns, respectively, selected via optimization, randomization, or metadata.
- Finite-sample valid P-value bound:
\[
P(|S| \ge s) \le 2\exp\left(-\frac{2s^2}{1 - \gamma}\right)
\]
where \( \gamma \) quantifies correlation between column embeddings and sample sizes.

#### 3. **Asymptotic Normality and P-value Approximation** {-}
- Provides theoretical proofs showing OASIS's statistic converges to a normal distribution asymptotically, allowing standard Gaussian approximation of P-values for large samples.
- Asymptotic approximation closely aligns with finite-sample bounds, incorporating a variance parameter \( \sigma_f^2 \) derived from the embedding vector \( f \).

---

### Statistical Variability and Randomness {-}

#### 1. **Randomness in Data-Splitting and Embeddings** {-}
- Implements data-splitting (training/test sets) to select optimal embedding vectors without statistical bias, ensuring validity via Bonferroni corrections for multiple splits.
- Contingency table counts are modeled explicitly as multinomial distributions under the null hypothesis, integrating randomness directly into theoretical guarantees.

#### 2. **Robustness to Variability (Overdispersion)** {-}
- OASIS explicitly addresses **overdispersion**, common in genomic data such as single-cell RNA sequencing, ensuring robustness.
- Simulations confirm OASIS maintains robust control of the false discovery rate (FDR), whereas Pearson’s X² often fails under similar conditions.

---

### Power and Performance {-}
- Simulations demonstrate that OASIS significantly outperforms Pearson’s X² in detecting structured deviations from the null hypothesis (e.g., distinct two-group scenarios).
- Conversely, OASIS shows lower power relative to Pearson’s X² in scenarios with diffuse, noisy signals, highlighting a clear trade-off emphasizing structured signal detection.

---

### Applications and Interpretability {-}
- OASIS successfully applied to genomic data, such as de novo detection of SARS-CoV-2 and Mycobacterium tuberculosis variants, outperforming existing methods without relying on reference genomes.
- Provides interpretability post-inference, clearly indicating why the null hypothesis was rejected via meaningful embedding vectors, in contrast to purely exploratory techniques like correspondence analysis.

---

### Statistical Validity and Effect Size {-}
- Defines a clear, intuitive effect size measure quantifying differences between groups identified by embeddings. This effect size is bounded by total variation distance, ensuring practical interpretability.
- Provides rigorous proofs for the finite-sample validity of its P-values using classical probability and concentration inequality arguments.

---

### Conclusions and Broader Implications {-}
- Highlights OASIS’s potential beyond contingency tables, offering a general framework potentially applicable to structured inference, matrix decomposition, and multi-table inference beyond standard singular value decomposition (SVD).

---

### Supplemental Information Highlights {-}
- Extensive mathematical proofs are provided, supporting theoretical claims regarding finite-sample validity, asymptotic normality, and embedding optimization.
- Additional simulations emphasize robustness, stability, and effectiveness of embedding optimization strategies under various statistical conditions.

---

**In summary**, OASIS provides a statistically rigorous, computationally efficient, robust, and interpretable alternative to Pearson’s X² test, particularly valuable in modern genomics and other domains dealing with high-dimensional, sparse, structured data.


<br/>
<br/>

<!--
### SciSpace Prompt {-} {-}

<br/>

### **Response**  {-}

<br/>

-->

## Scholar GPT Prompt {-}

* Please provide a summary of the technical content of the attached article,
`OASIS` ( Baharav et al., 2024 [@Baharav:2024aa]),
paying particular attention to statistical
aspects of the mothodologies or any component
which is prey to randomness or variability.

* `"OASIS: An interpretable, finite-sample valid alternative to Pearson’s X² for scientific discovery" 



<br/>


## **Response**  {-}

### Home {-}

<br/>


* Technical Summary of OASIS (Baharav et al., 2024)

> *Baharav, T. Z., Tse, D., & Salzman, J. (2024). OASIS: An interpretable, finite-sample valid alternative to Pearson’s X² for scientific discovery. Proceedings of the National Academy of Sciences, 121(15), e2304671121. [https://doi.org/10.1073/pnas.2304671121](https://doi.org/10.1073/pnas.2304671121)*

### 🔍 Overview  {-}

OASIS (Optimized Adaptive Statistic for Inferring Structure) is a family of statistical tests designed for **contingency table analysis**, providing:

- Finite-sample valid p-values
- Closed-form bounds
- Interpretability through a linear test-statistic
- Better robustness to noise and overdispersion than Pearson’s χ² test

It is particularly suited for **sparse and high-dimensional data**, such as those arising in genomics.

---

### 🧮 Test Statistic  {-}

Given a count matrix \( X \in \mathbb{N}^{I \times J} \), the OASIS test statistic is:

\[
S = f^\top \tilde{X} c
\]

Where:
- \( f \in \mathbb{R}^I \): row embedding vector
- \( c \in \mathbb{R}^J \): column embedding vector
- \( \tilde{X} \): the centered and column-normalized matrix

This structure allows for **signal aggregation** and **dampening of noise** through linear algebraic properties.

---

### 📊 Statistical Randomness and Finite-Sample Validity  {-}

#### Reformulation via Latent Variables  {-}

Each table cell count \( X_{i,j} \) is constructed from i.i.d. latent variables:

\[
Z_{j,k} \sim p, \quad X_{i,j} = \sum_{k=1}^{n_j} \mathbb{1}\{Z_{j,k} = i\}
\]

This allows \( S \) to be written as a **weighted sum of independent random variables**, enabling concentration bounds.

---

#### Finite-Sample p-Value Bound  {-}

Using **Hoeffding’s inequality**, the authors derive:

\[
P(|S| \geq s) \leq 2 \exp\left( \frac{-2s^2}{1 - \gamma} \right)
\]

Where:

\[
\gamma = \left( \frac{\sum_j c_j \sqrt{n_j}}{\sqrt{M} \|c\|} \right)^2, \quad M = \sum_j n_j
\]

- This is valid for any fixed \( f, c \)
- Ensures **exact control** of type I error for **any sample size**

---

### 📈 Asymptotic Normality  {-}

The statistic converges to a normal distribution as sample sizes increase:

\[
\frac{1}{\sqrt{1 - \gamma}} S \xrightarrow{D} \mathcal{N}(0, \sigma_f^2 \|c\|^2)
\]

Where:

\[
\sigma_f^2 = \text{Var}_{Z \sim p}(f_Z)
\]

- Derived via **Lyapunov’s Central Limit Theorem**
- Ensures smooth transition between finite-sample and asymptotic inference

---

### 🧪 Effect Size  {-}

OASIS defines an **effect size estimate**:

\[
\hat{\Delta} = \left| \mathbb{E}_{p_A}[f_Z] - \mathbb{E}_{p_B}[f_Z] \right|
\]

- Measures difference between two groups
- Upper bounded by **total variation distance** \( \delta_{TV}(p_A, p_B) \)
- Ensures effect size is biologically meaningful

---

### 🔁 Data-Splitting Validity  {-}

To avoid overfitting:
- Data is split into train/test sets
- Embeddings \( f \), \( c \) are learned on train, evaluated on test
- The p-value remains valid under classical **data-splitting logic**:

\[
P(p(X) \leq u) \leq u
\]

Multiple random splits are allowed, with **Bonferroni correction** to maintain error control.

---

### 📚 Comparison with Pearson’s χ²  {-}

| Feature | Pearson χ² | OASIS |
|--------|-------------|--------|
| P-values | Asymptotic | Finite-sample valid |
| Residual Aggregation | Squared sum | Bilinear form |
| Normalization | Rows & columns | Columns only |
| Interpretability | Post-hoc via SVD | Built-in |
| Robustness | Poor (esp. overdispersion) | Strong |

---

### ✅ Conclusion  {-}

OASIS offers:
- Closed-form finite-sample p-value bounds
- Asymptotic normality
- Interpretability through test structure
- High performance in noisy, sparse biological data

It is a rigorous, modern replacement for χ² tests in scientific discovery contexts, especially genomics.

---

### 📘 Reference  {-}

Baharav, T. Z., Tse, D., & Salzman, J. (2024). *OASIS: An interpretable, finite-sample valid alternative to Pearson’s X² for scientific discovery*. *PNAS*, **121**(15), e2304671121.  
👉 [DOI Link](https://doi.org/10.1073/pnas.2304671121)


# SPLASH and OASIS Citation Litetature {#splash-oasis-citings .tabset}

## Home {-}

<br/>
<br/>

## Ask chatGPT {-}

* Prompt: Which AI research assistants are best for surveying the most recent literature for citings of a particulat articale?

* Response:

Here are some of the best AI-driven tools specifically suited to finding recent literature and citations of a particular article:

### Best Tools for Citation Tracking and Literature Discovery: {-}

1. **ResearchRabbit**
   - **Strengths:** AI-powered literature discovery, finds recent citations, visualizes citation networks.
   - **Use case:** Quickly visualize and explore articles citing your target paper, including the newest ones.
   - **Website:** [researchrabbit.ai](https://www.researchrabbit.ai/)

2. **Connected Papers**
   - **Strengths:** Creates visual graphs of related research papers, efficiently surfacing new papers citing a given article.
   - **Use case:** Find recent and related publications visually in seconds.
   - **Website:** [connectedpapers.com](https://www.connectedpapers.com/)

3. **Scite.ai**
   - **Strengths:** Analyzes citations contextually (supporting, contrasting, or neutral), and quickly finds recent citations to a specific article.
   - **Use case:** Understand not just who cites the paper, but how it's discussed.
   - **Website:** [scite.ai](https://scite.ai/)

4. **Semantic Scholar**
   - **Strengths:** AI-driven search and literature discovery; good at surfacing newer papers citing a particular source.
   - **Use case:** Finding and tracking highly relevant and recent literature through powerful filters.
   - **Website:** [semanticscholar.org](https://www.semanticscholar.org/)

5. **Elicit**
   - **Strengths:** AI-powered literature surveys, extracts key insights, and tracks citation influence efficiently.
   - **Use case:** Quickly create structured literature reviews and citation tracking summaries.
   - **Website:** [elicit.org](https://elicit.org/)

### Recommended Workflow: {-}

- **Start with ResearchRabbit or Connected Papers** to visually see a map of recent citations and related works.
- Use **Semantic Scholar** to narrow results with sophisticated filters (year, citation count, fields).
- Then apply **Scite.ai** to evaluate the context and impact of these citations.
- For deeper analysis and summarization, **Elicit** can be used to generate a structured review.

This combination provides a comprehensive AI-assisted workflow for effectively tracking recent citations of any given article.

<br/>
<br/>

## scite_ {-}

* RETURN TO THIS LATER
   - there has not been enough time for OASIS citations to appear.

# Appendix 

## chatGPT Technical Terms {-}

* chatGPT query:
   - what is the best GPT based tool to obtain definitions of technical terms used in biotech related scientific publications?

* Response
   - Best GPT-based tools for defining technical terms in biotech-related scientific publications:

| Tool | Strengths | Ideal Usage |
|------|-----------|-------------|
| **[SciSpace Copilot](https://scispace.com)** | - Contextual definitions within scientific papers<br>- Highly accurate for biotech terms<br>- Integrated directly into research PDFs | Immediate comprehension within biotech research papers |
| **[Elicit.org](https://elicit.org)** | - GPT-powered scientific research assistant<br>- Simplifies technical jargon into plain language<br>- Effective for quick clarification | Rapid clarification and concise definitions |
| **[Explainpaper](https://www.explainpaper.com)** | - GPT-driven academic language translator<br>- Clear, user-friendly explanations of complex biotech concepts | Students or researchers seeking straightforward definitions |
| **[Consensus](https://consensus.app)** | - Aggregates and summarizes definitions from multiple scientific papers<br>- Provides context-aware definitions within the broader biotech field | Cross-validating definitions across multiple sources |
|

#### Recommended overall choice:  {-}
- ✅ **[SciSpace Copilot](https://scispace.com)** is the best overall choice for its contextual accuracy and specialized biotech literature integration.^[
The SciSpace Copilot interface is not intuitive at this point - use alternative
]

**Alternatives:** Use **Elicit** or **Consensus** if definitions from broader perspectives or cross-validation across sources is desired.

<br/>

## GPT-Based Research Assistants {#App-GPT-based-res .tabset -}

* Compare the resuts when chatGPT is asked about 4 assistants
with those when 6 assistants were included (Section \@ref(GPT-based-res).

<br/>

### Home {-}

<br/>
<br/>

### chatGPT Prompt - 4 tools {-}

* Refer to the articles uploaded to the project - 

   - Chaung, K., Baharav, T.Z., Henderson, G., Zheludev, I.N., Wang, P.L., and Salzman, J. (2023). SPLASH: A statistical, reference-free genomic algorithm unifies biological discovery. Cell 186, 5440–5456.
2.

   - Baharav, T.Z., Tse, D., and Salzman, J. (2024). OASIS: An interpretable, finite-sample valid alternative to pearson’s x(2) for scientific discovery. Proc Natl Acad Sci U S A 121, e2304671121. -
to get a sense of the `reference-free genomic inference` context.


* Compare and contrast 4 research tools - 
Scholar GPT, Concensus, SciSpace, Semantic Scholar -
in their strengths and weaknesses when used to establish
the state of the art for knowledge  around reference-free genomics



<br/>


### **Response** {-}

It appears the files "SPLASH" (Chaung et al., 2023) and "OASIS" (Baharav et al., 2024) are now uploaded and accessible.

I will briefly outline the key points about these two reference-free genomic inference methods from the uploaded articles before proceeding to compare the four research tools.

<br/>

#### Overview of Uploaded Articles: {-}

##### 1. SPLASH (Chaung et al., 2023): {-}
- Introduces SPLASH, a statistical, reference-free algorithm designed to 
<span style="color:darkgreen">unify</span>^[
What does `unify` mean here?
]genomic analysis without relying on predefined genomic references.
- Uses statistical methods to detect genomic events such as splicing, structural variants, and microbiome composition directly from sequencing data without alignment.
   -  Contingency table summary statistics which have known distributions under
independent assortments can be computed and analyzed in order to idendify rare genomic
events.   
   - Sensible "statistical" filters tend to work, more or less.  The key is to 
collect the necessary data and do rhe necessary analyses tp arrive at an accurate
and detailed assessment of performance on a meaningful scale.
- Highlights the potential for broader biological discovery without the bias introduced by standard reference genomes.
   - it would be good to have a comrehensive sense of estrimates of bias and variability
so that compaerisons can be made between the with and without referen e ana1lyses.

<br/>

##### 2. OASIS (Baharav et al., 2024): {-}
- Presents OASIS as an interpretable alternative to Pearson’s χ², specifically tailored for genomic data analysis.
- It emphasizes interpretability, finite-sample validity, and robustness, particularly suited for identifying rare and novel biological phenomena from genomic data.
- Demonstrates applicability across different genomic datasets, making it powerful in uncovering insights that traditional reference-dependent or common statistical tests might miss.

---

#### Comparison of Research Tools for Establishing State-of-the-Art Knowledge in Reference-Free Genomics: {-}

| Tool             | Strengths (Context: reference-free genomics)                                                     | Weaknesses (Context: reference-free genomics)                          |
|------------------|--------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|
| Scholar GPT      | - Good at clarifying complex statistical methods (e.g., SPLASH and OASIS).<br>- Effective for synthesizing novel methods and their implications.<br>- Ideal for interactive learning about method-specific details. | - Dependent on clarity and quality of uploaded or included context.<br>- May occasionally generalize details when nuanced interpretation is needed. |
| Consensus        | - Efficient at quickly summarizing consensus points and widely accepted findings.<br>- Useful to quickly gauge acceptance or prominence of SPLASH or OASIS within the broader community. | - Might not effectively highlight emerging, nuanced approaches like OASIS, especially before extensive citation or wider adoption. |
| SciSpace         | - Strong at in-depth explanation and breaking down complicated statistical procedures and experimental design, as found in SPLASH and OASIS.<br>- Helpful for direct clarification of specific, technical content. | - Less effective in comparative literature review; typically focused on one paper at a time rather than establishing cross-paper, state-of-the-art status. |
| Semantic Scholar | - Excellent at identifying influential works and creating citation-based knowledge networks.<br>- Provides comprehensive overviews of research lineage and impact, ideal for seeing SPLASH or OASIS positioning in the wider research context. | - May miss detailed, methodological nuances if those nuances aren’t widely cited or easily discoverable via citation metrics alone.<br>- Not ideal for direct methodological clarification. |

---

#### Recommended Use Cases in the Context of Reference-Free Genomics: {-}

- **Scholar GPT and SciSpace**: Best for deep-diving into the details of complex, innovative methods like SPLASH and OASIS.
- **Consensus**: Ideal for quickly establishing the perceived reliability and adoption of SPLASH or OASIS methodologies within the genomic community.
- **Semantic Scholar**: Most effective for understanding historical and contextual positioning, tracking methodological influence, and recognizing highly cited seminal works that frame state-of-the-art reference-free genomic methods.

Let me know if you'd like further details or assistance on a particular aspect.

<br/>
<br/>


## Multinomial Distance Metrics 

* This `D` is different than the D is SPLASH
   - should behave similarly when total counts are similar
   - with no scaling and doing the math on the linear scale is interesting

<br/>

You've provided two multinomial distributions \(P\) and \(Q\), defined as:

\[
P = \{p_1, p_2, \dots, p_n\}, \quad Q = \{q_1, q_2, \dots, q_n\}
\]

and defined a distance metric \(D\) as:

\[
D = 1 - \frac{\sum_{i=1}^{n}\min(p_i, q_i)}{\sum_{i=1}^{n}(p_i + q_i)}
\]

---

### Step-by-step analysis of the defined metric \( D \): {-}

**Step 1: Interpretation**

- The numerator \(\sum_{i=1}^{n}\min(p_i, q_i)\) measures the **overlap** between the two distributions.
- The denominator \(\sum_{i=1}^{n}(p_i + q_i)\) is simply the sum of all probabilities from both distributions, and if both distributions sum to 1 (i.e., are probability distributions), this denominator equals exactly \(1 + 1 = 2\).

Thus, assuming valid probability distributions (\(\sum p_i = 1\), \(\sum q_i = 1\)), the formula simplifies to:

\[
D = 1 - \frac{\sum_{i=1}^{n}\min(p_i, q_i)}{2}
\]

---

### Step 2: Properties of \( D \) {-}

- **Range**:  
  Since \(0 \leq \sum_{i}\min(p_i, q_i) \leq 1\), it follows that:
  - Minimum possible value: If \(P = Q\), then \(\sum\min(p_i,q_i)=1\), and thus:
  \[
  D = 1 - \frac{1}{2} = 0.5
  \]
  *(This indicates your provided formula might have a slight issue if your intention is that distance should be 0 when \(P=Q\). Typically, distance measures satisfy \(D(P,Q)=0\) if and only if \(P=Q\). The current formulation does not satisfy this.)*

- **When are P and Q completely disjoint?**  
  If \(P\) and \(Q\) do not overlap at all (no common support), then \(\sum\min(p_i,q_i)=0\), thus:
  \[
  D = 1 - \frac{0}{2} = 1
  \]

Thus, according to your current formula:

- Completely identical distributions \(P=Q\) yield \(D=0.5\).
- Completely distinct distributions yield \(D=1\).

If you intended to measure similarity or overlap, the standard formulation should typically be either:

\[
D_{standard} = 1 - \sum_{i}\min(p_i,q_i)
\]

or

\[
D_{normalized} = 1 - \frac{\sum_{i}\min(p_i,q_i)}{\sum_{i}\max(p_i,q_i)}
\]

These alternative definitions yield the intuitive property: \(D(P,Q)=0\) if \(P=Q\).

---

### Step 3: Suggested corrected metric {-}

If your goal is to define a metric distance measure between distributions, a commonly used overlap-based measure is:

\[
D'(P,Q) = 1 - \sum_{i=1}^{n}\min(p_i,q_i)
\]

Properties of this standard metric:

- Range: \([0,1]\)
- \(D'(P,Q)=0\) if and only if \(P=Q\)
- \(D'(P,Q)=1\) if distributions are completely disjoint.

---

### **Summary:** {-}

| Metric | Definition | Range | \(P=Q\) | Disjoint \(P,Q\) |
|---|---|---|---|---|
| Your Provided Metric \(D\) | \(1 - \frac{\sum\min(p_i,q_i)}{\sum(p_i+q_i)}\) | [0.5,1] | 0.5 (unusual) | 1 |
| Standard Overlap Distance \(D'\) | \(1-\sum\min(p_i,q_i)\) | [0,1] | 0 (intuitive) | 1 |

---

### **Conclusion and Recommendation:** {-}

- Your given metric is mathematically valid but has an unusual property of having a nonzero lower bound (0.5) even when distributions are identical.
- If the intention is to measure a meaningful distance between two probability distributions (multinomial), **consider using the standard overlap metric \(D'\)** above, which provides intuitive and desirable properties for practical applications:

\[
\boxed{D'(P,Q) = 1 - \sum_{i=1}^{n}\min(p_i,q_i)}
\]

If you have a specific reason for choosing your original formula, please clarify so I can adjust accordingly.

<br/>
<br/>

# References {-} 
<div id="refs"></div>
    
<br/>

<!-- 
## Parameter settings {-}
  * WRKDIR = `r normalizePath(WRKDIR)`
  * FN = `r FN`
  * Scripts = Scripts
  * RUN DATE = `r date()`

```{r m2a-session-info, echo=T, eval=F}
 sessionInfo()
```
-->

```{r, echo=FALSE}
  knit_exit()
```

#######################################################################
## ARCHIVAL
#######################################################################


## What is a Statistical Algorithm?

* Submitted to SciSpace (copilot)

A **statistical algorithm** is a computational procedure that applies statistical techniques to analyze data, make predictions, or identify patterns. These algorithms use probability theory, statistical inference, and mathematical modeling to extract meaningful insights from data. They are widely used in fields such as machine learning, data science, econometrics, and bioinformatics.

### Key Characteristics:
1. **Data-Driven**: Statistical algorithms rely on observed data to make estimations or predictions.
2. **Probabilistic Nature**: They incorporate probability distributions to model uncertainties.
3. **Optimization-Based**: Many involve optimization techniques to minimize errors and improve accuracy.
4. **Inference and Estimation**: They estimate parameters, test hypotheses, and infer relationships.

### Examples of Statistical Algorithms:
- **Regression Models**: Linear Regression, Logistic Regression
- **Classification Models**: Naïve Bayes, Decision Trees (with statistical criteria like Gini Impurity or Entropy)
- **Clustering Methods**: K-Means, Gaussian Mixture Models (GMM)
- **Dimensionality Reduction**: Principal Component Analysis (PCA), Singular Value Decomposition (SVD)
- **Bayesian Inference**: Markov Chain Monte Carlo (MCMC), Hidden Markov Models (HMM)

### Applications:
- **Machine Learning**: Feature selection, model training, and prediction.
- **Finance**: Risk assessment, stock market predictions.
- **Healthcare**: Disease diagnosis, medical imaging analysis.
- **Social Sciences**: Survey analysis, behavioral predictions.

In essence, statistical algorithms form the backbone of data-driven decision-making, allowing machines and researchers to extract patterns, make predictions, and improve decision accuracy.


<br/>
<br/>


## What is Biological Inference?

* Submitted to SciSpace (copilot)

**Poor definition.**

**Biological inference** refers to the process of drawing conclusions about biological systems, processes, or phenomena using data analysis, statistical models, and computational methods. It involves using observed biological data to make predictions, identify patterns, or infer underlying mechanisms.

<br/>

### Key Aspects of Biological Inference:
1. **Data-Driven Analysis**: Utilizes experimental or observational biological data.
2. **Statistical and Computational Models**: Applies statistical inference, machine learning, and bioinformatics tools.
3. **Hypothesis Testing**: Evaluates scientific hypotheses based on data.
4. **Predictive Insights**: Helps predict biological behaviors and interactions.

<br/>

### Examples of Biological Inference:
- **Genomic Inference**: Identifying genetic variations linked to diseases.
- **Phylogenetic Inference**: Reconstructing evolutionary relationships among species.
- **Protein Structure Prediction**: Inferring 3D structures from amino acid sequences.
- **Ecological Inference**: Understanding species distribution and population dynamics.
- **Systems Biology**: Modeling complex biological networks and interactions.

<br/>

### Applications:
- **Medicine**: Predicting disease susceptibility and drug responses.
- **Evolutionary Biology**: Understanding the genetic basis of adaptation.
- **Ecology**: Assessing environmental impacts on biodiversity.
- **Bioinformatics**: Analyzing large-scale biological datasets.

biological inference plays a crucial role in advancing our understanding of life sciences 
by integrating data-driven approaches to uncover hidden patterns and 
relationships in biological systems.




### chatGPT Prompt {-}

* Read the attached paper by Sood et.al. 2015 [@Sood:2015aa].

* Act as a statistician who is proficient in the traditional statistical concepts as they apply to the analysis of designed experiments, as well as in the novel statistical concepts developed for the analysis of omic data, and review the article.

* The review should not consider findings from later studies

* The review should focus on the statistical aspects of the data collected and analysed.
* Key statistical principles include:
  - verifying that the training data points can be thought of as being
a representative, random subset of the target population
  - a representative subset most include enough of the right sort of sample.
   - how many data collection runs are aggregated or pooled to assemble the analysis dataset?
   - how are the different tissue types distributed across data generation runs?  
   - Is run associated with age. 
   - Were the data from different runs normalized?
* What evidence is provided that the classifiers developed work well with datasets analyzed and will continue to work well when future data are analyzed?

* Keep the report in un-rendered markdown format, or markdown syntax.
* Also include the markdown syntax for a bibliography of citations.

<br/>

### chatGPT RE:Prompt {-}

Note that what the authors  call external validation  entails fitting a new model with each dataset.  There is no validation of a model; only validation that the subset of 150 probe sets are sufficient to enable KNN + LOOCV to give rise to a fitted model that still discriminates.  This is not validation in the usual sense.  There is no attempt to compare the fitted models from the different data sets.  Jacob and Speed (attached) show that repeating the fit and eval procedures with a random selection of 150 probe sets achieves similar discrimination on some datasets.
Please include these facts in the conclusions to be drawn form these data.

<br/>

* The review should not consider findings from later studies

* The review should focus on the statistical aspects of the data collected and analysed.
* Key statistical principles include:
   - how are the different tissue types distributed across data generation runs?  
   - Is run associated with age. 
   - Were the data from different runs normalized?
* What evidence is provided that the classifiers developed work well with datasets analyzed and will continue to work well when future data are analyzed?

* Keep the report in un-rendered markdown format, or markdown syntax.
* Also include the markdown syntax for a bibliography of citations.


<br/>
<br/>


<!-- To run
## nohup Rscript -e "knitr::knit2html('_M2A-RFGI_SPLASH_v1.Rmd')" > _M2A-RFGI_SPLASH_v1.log  &

## Or
## nohup Rscript -e "rmarkdown::render('_M2A-RFGI_SPLASH_v1.Rmd')" > _M2A-RFGI_SPLASH_v1.log  &

-->

